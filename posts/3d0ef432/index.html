<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>特征工程(VI)--机器学习 | 雷小小</title><meta name="author" content="Tiny Lei"><meta name="copyright" content="Tiny Lei"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Jupyter Notebook 代码连接：machine_learning_demo  Step 1: Imports and Configuration import pandas as pdimport numpy as npimport copyimport jsonimport pickleimport joblibimport lightgbm as lgbimport optunai">
<meta property="og:type" content="article">
<meta property="og:title" content="特征工程(VI)--机器学习">
<meta property="og:url" content="https://wilenwu.gitee.io/posts/3d0ef432/index.html">
<meta property="og:site_name" content="雷小小">
<meta property="og:description" content="Jupyter Notebook 代码连接：machine_learning_demo  Step 1: Imports and Configuration import pandas as pdimport numpy as npimport copyimport jsonimport pickleimport joblibimport lightgbm as lgbimport optunai">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://wilenwu.gitee.io/img/FeatureEngine.png">
<meta property="article:published_time" content="2024-04-20T08:40:52.000Z">
<meta property="article:modified_time" content="2024-04-20T15:44:01.798Z">
<meta property="article:author" content="Tiny Lei">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="python">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://wilenwu.gitee.io/img/FeatureEngine.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://wilenwu.gitee.io/posts/3d0ef432/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="baidu-site-verification" content="code-7rymn5Bitx"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?654e7415ab55bed7c9c2bc6d665f03c5";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '特征工程(VI)--机器学习',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-04-20 23:44:01'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="//at.alicdn.com/t/font_2849223_xh1ftc8qym.css"><link rel="stylesheet" href="/css/link-card.css"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script src="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.0.0"><link rel="alternate" href="/atom.xml" title="雷小小" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">168</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">107</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">43</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/user-guide/"><i class="fa-fw fa fa-compass"></i><span> 用户指南</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fa-fw fa fa-book"></i><span> 文档</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/gallery/"><i class="fa-fw fa fa-images"></i><span> 图库</span></a></div><div class="menus_item"><a class="site-page" href="/ebook/"><i class="fa-fw fa fa-book-reader"></i><span> 电子书</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-star"></i><span> 收藏夹</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fa-fw fa-solid fa-circle-chevron-down"></i><span> 更多</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/about/"><i class="fa-fw fa fa-user"></i><span> 关于我</span></a></li><li><a class="site-page child" href="/analytics/"><i class="fa-fw fa fa-line-chart"></i><span> 文章统计</span></a></li><li><a class="site-page child" href="/log/"><i class="fa-fw fa fa-history"></i><span> 更新日志</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/python-top-img.svg')"><nav id="nav"><span id="blog-info"><a href="/" title="雷小小"><img class="site-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/favicon.png"/><span class="site-name">雷小小</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/user-guide/"><i class="fa-fw fa fa-compass"></i><span> 用户指南</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fa-fw fa fa-book"></i><span> 文档</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/gallery/"><i class="fa-fw fa fa-images"></i><span> 图库</span></a></div><div class="menus_item"><a class="site-page" href="/ebook/"><i class="fa-fw fa fa-book-reader"></i><span> 电子书</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-star"></i><span> 收藏夹</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fa-fw fa-solid fa-circle-chevron-down"></i><span> 更多</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/about/"><i class="fa-fw fa fa-user"></i><span> 关于我</span></a></li><li><a class="site-page child" href="/analytics/"><i class="fa-fw fa fa-line-chart"></i><span> 文章统计</span></a></li><li><a class="site-page child" href="/log/"><i class="fa-fw fa fa-history"></i><span> 更新日志</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">特征工程(VI)--机器学习<a class="post-edit-link" href="https://gitee.com/WilenWu/myblog/edit/master/source/_posts/python/Feature-Engineering-with-Python(VI)--Machine-Learning.md" rel="external nofollow noreferrer" title="编辑" target="_blank"><i class="fas fa-pencil-alt"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-04-20T08:40:52.000Z" title="发表于 2024-04-20 16:40:52">2024-04-20</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-04-20T15:44:01.798Z" title="更新于 2024-04-20 23:44:01">2024-04-20</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/python/">Python</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/python/machine-learning/">Machine Learning</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>29分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="特征工程(VI)--机器学习"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>Jupyter Notebook 代码连接：<a href="/ipynb/machine_learning_demo">machine_learning_demo</a></p>
<h1 id="step-1-imports-and-configuration"><a class="markdownIt-Anchor" href="#step-1-imports-and-configuration"></a> Step 1: Imports and Configuration</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> joblib</span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"><span class="keyword">import</span> optuna</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">import</span> gc</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve, roc_auc_score, recall_score, accuracy_score, fbeta_score, precision_score</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split, cross_val_score, KFold</span><br><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> clone</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="comment"># Setting configuration.</span></span><br><span class="line">pd.set_option(<span class="string">&#x27;display.float_format&#x27;</span>, <span class="keyword">lambda</span> x: <span class="string">&#x27;%.5f&#x27;</span> %x)</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line">sns.set_style(<span class="string">&#x27;whitegrid&#x27;</span>)</span><br><span class="line">optuna.logging.set_verbosity(optuna.logging.WARNING)</span><br><span class="line"></span><br><span class="line">SEED = <span class="number">42</span></span><br></pre></td></tr></table></figure>
<h1 id="step-2-load-the-datasets"><a class="markdownIt-Anchor" href="#step-2-load-the-datasets"></a> Step 2: Load the datasets</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Loading data...&#x27;</span>)</span><br><span class="line">path = <span class="string">&#x27;../datasets/Home-Credit-Default-Risk/&#x27;</span></span><br><span class="line">df = pd.read_csv(path + <span class="string">&#x27;selected_data.csv&#x27;</span>, index_col=<span class="string">&#x27;SK_ID_CURR&#x27;</span>) </span><br></pre></td></tr></table></figure>
<pre><code>Loading data...
</code></pre>
<p>定义帮助节省内存的函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_dtypes</span>(<span class="params">df, verbose=<span class="literal">True</span></span>):</span></span><br><span class="line">    original_memory = df.memory_usage().<span class="built_in">sum</span>()</span><br><span class="line">    df = df.apply(pd.to_numeric, errors=<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Convert booleans to integers</span></span><br><span class="line">    boolean_features = df.select_dtypes(<span class="built_in">bool</span>).columns.tolist()</span><br><span class="line">    df[boolean_features] = df[boolean_features].astype(np.int32)</span><br><span class="line">     <span class="comment"># Convert objects to category</span></span><br><span class="line">    object_features = df.select_dtypes(<span class="built_in">object</span>).columns.tolist()</span><br><span class="line">    df[object_features] = df[object_features].astype(<span class="string">&#x27;category&#x27;</span>)</span><br><span class="line">    <span class="comment"># Float64 to float32</span></span><br><span class="line">    float_features = df.select_dtypes(<span class="built_in">float</span>).columns.tolist()</span><br><span class="line">    df[float_features] = df[float_features].astype(np.float32)</span><br><span class="line">    <span class="comment"># Int64 to int32</span></span><br><span class="line">    int_features = df.select_dtypes(<span class="built_in">int</span>).columns.tolist()</span><br><span class="line">    df[int_features] = df[int_features].astype(np.int32)</span><br><span class="line">        </span><br><span class="line">    new_memory = df.memory_usage().<span class="built_in">sum</span>()</span><br><span class="line">    <span class="keyword">if</span> verbose:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Original Memory Usage: <span class="subst">&#123;<span class="built_in">round</span>(original_memory / <span class="number">1e9</span>, <span class="number">2</span>)&#125;</span> gb.&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;New Memory Usage: <span class="subst">&#123;<span class="built_in">round</span>(new_memory / <span class="number">1e9</span>, <span class="number">2</span>)&#125;</span> gb.&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> df</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Training dataset shape: &quot;</span>, df.shape)</span><br></pre></td></tr></table></figure>
<pre><code>Training dataset shape:  (307511, 836)
</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = convert_dtypes(df)</span><br></pre></td></tr></table></figure>
<pre><code>Original Memory Usage: 2.06 gb.
New Memory Usage: 1.0 gb.
</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.dtypes.value_counts()</span><br></pre></td></tr></table></figure>
<pre><code>float32     796
int32         7
category      3
category      3
category      3
category      3
category      3
category      2
category      2
category      2
category      1
category      1
category      1
category      1
category      1
category      1
category      1
category      1
category      1
category      1
category      1
category      1
Name: count, dtype: int64
</code></pre>
<h1 id="step-3-data-preprocessing"><a class="markdownIt-Anchor" href="#step-3-data-preprocessing"></a> Step 3: Data preprocessing</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Check if the data is unbalanced</span></span><br><span class="line">df[<span class="string">&quot;TARGET&quot;</span>].value_counts()</span><br></pre></td></tr></table></figure>
<pre><code>TARGET
0    282686
1     24825
Name: count, dtype: int64
</code></pre>
<p>数据集存在轻微的样本不平衡，我们接下来测试几种处理方法，来提高模型表现。</p>
<p>先定义评估函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">timer</span>(<span class="params">func</span>):</span></span><br><span class="line">    <span class="keyword">import</span> time</span><br><span class="line">    <span class="keyword">import</span> functools</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">strfdelta</span>(<span class="params">tdelta, fmt</span>):</span></span><br><span class="line">        hours, remainder = <span class="built_in">divmod</span>(tdelta, <span class="number">3600</span>)</span><br><span class="line">        minutes, seconds = <span class="built_in">divmod</span>(remainder, <span class="number">60</span>)</span><br><span class="line">        <span class="keyword">return</span> fmt.<span class="built_in">format</span>(hours, minutes, seconds)</span><br><span class="line"><span class="meta">    @functools.wraps(<span class="params">func</span>)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wrapper</span>(<span class="params">*args, **kwargs</span>):</span></span><br><span class="line">        click = time.time()</span><br><span class="line">        result = func(*args, **kwargs)</span><br><span class="line">        delta = strfdelta(time.time() - click, <span class="string">&quot;&#123;:.0f&#125; hours &#123;:.0f&#125; minutes &#123;:.0f&#125; seconds&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;func.__name__&#125;</span> cost time <span class="subst">&#123;delta&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define a cross validation strategy</span></span><br><span class="line"><span class="comment"># We use the cross_val_score function of Sklearn. </span></span><br><span class="line"><span class="comment"># However this function has not a shuffle attribute, we add then one line of code, </span></span><br><span class="line"><span class="comment"># in order to shuffle the dataset prior to cross-validation</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@timer</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span>(<span class="params">model, X, y, n_folds = <span class="number">5</span>, params=<span class="literal">None</span></span>):</span></span><br><span class="line">    kf = KFold(n_folds, shuffle=<span class="literal">True</span>, random_state=SEED).get_n_splits(X)</span><br><span class="line">    scores = cross_val_score(</span><br><span class="line">        model, </span><br><span class="line">        X, </span><br><span class="line">        y, </span><br><span class="line">        scoring=<span class="string">&quot;roc_auc&quot;</span>, </span><br><span class="line">        cv = kf,</span><br><span class="line">        verbose=<span class="number">1</span>,</span><br><span class="line">        params=params</span><br><span class="line">    )</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;valid auc: <span class="subst">&#123;scores.mean():<span class="number">.3</span>f&#125;</span> +/- <span class="subst">&#123;scores.std():<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> scores.mean()</span><br></pre></td></tr></table></figure>
<h2 id="split-data"><a class="markdownIt-Anchor" href="#split-data"></a> Split data</h2>
<p>留25%作为模型的验证集</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Split data into training and testing sets</span></span><br><span class="line">X_train, X_valid, y_train, y_valid = train_test_split(</span><br><span class="line">    df.drop(columns=<span class="string">&quot;TARGET&quot;</span>), </span><br><span class="line">    df[<span class="string">&quot;TARGET&quot;</span>], </span><br><span class="line">    test_size=<span class="number">0.25</span>, </span><br><span class="line">    random_state=SEED</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;X_train shape:&quot;</span>, X_train.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;train:&#x27;</span>, y_train.value_counts(), sep=<span class="string">&#x27;\n&#x27;</span>) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;valid:&#x27;</span>, y_valid.value_counts(), sep=<span class="string">&#x27;\n&#x27;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>X_train shape: (230633, 835)
train:
TARGET
0    211999
1     18634
Name: count, dtype: int64
valid:
TARGET
0    70687
1     6191
Name: count, dtype: int64
</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">del</span> df</span><br><span class="line">gc.collect()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Specific feature names and categorical features</span></span><br><span class="line">feature_name = X_train.columns.tolist()</span><br><span class="line">categorical_feature = X_train.select_dtypes(<span class="string">&#x27;category&#x27;</span>).columns.tolist()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.compose <span class="keyword">import</span> make_column_transformer</span><br><span class="line"></span><br><span class="line"><span class="comment"># Encode categorical features</span></span><br><span class="line">encoder = make_column_transformer(</span><br><span class="line">    (OneHotEncoder(</span><br><span class="line">        drop=<span class="string">&#x27;if_binary&#x27;</span>, </span><br><span class="line">        min_frequency=<span class="number">0.02</span>, </span><br><span class="line">        max_categories=<span class="number">20</span>, </span><br><span class="line">        sparse_output=<span class="literal">False</span>,</span><br><span class="line">        handle_unknown=<span class="string">&#x27;ignore&#x27;</span></span><br><span class="line">    ), categorical_feature),</span><br><span class="line">    remainder=<span class="string">&#x27;passthrough&#x27;</span>, </span><br><span class="line">    verbose_feature_names_out=<span class="literal">False</span>,</span><br><span class="line">    verbose=<span class="literal">True</span>    </span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;fitting...&#x27;</span>)</span><br><span class="line">encoder.fit(X_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;encoding...&#x27;</span>)</span><br><span class="line">train_dummies = encoder.transform(X_train)</span><br><span class="line">valid_dummies = encoder.transform(X_valid)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;train data shape:&#x27;</span>, X_train.shape)</span><br></pre></td></tr></table></figure>
<pre><code>fitting...
[ColumnTransformer] . (1 of 2) Processing onehotencoder, total=   4.2s
[ColumnTransformer] ..... (2 of 2) Processing remainder, total=   0.0s
encoding...
train data shape: (230633, 835)
</code></pre>
<h2 id="model-1-use-default-parameters"><a class="markdownIt-Anchor" href="#model-1-use-default-parameters"></a> model 1: Use default parameters</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = lgb.LGBMClassifier(</span><br><span class="line">    boosting_type=<span class="string">&#x27;gbdt&#x27;</span>,</span><br><span class="line">    objective=<span class="string">&#x27;binary&#x27;</span>,</span><br><span class="line">    metric=<span class="string">&#x27;auc&#x27;</span>,</span><br><span class="line">    n_estimators=<span class="number">500</span>,</span><br><span class="line">    random_state=SEED,</span><br><span class="line">    verbose=<span class="number">0</span></span><br><span class="line">)</span><br><span class="line">fit_params = <span class="built_in">dict</span>(</span><br><span class="line">    callbacks = [lgb.early_stopping(<span class="number">20</span>)],</span><br><span class="line">    eval_set = [(train_dummies, y_train), (valid_dummies, y_valid)]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">score = evaluate(model, train_dummies, y_train, params=fit_params)</span><br></pre></td></tr></table></figure>
<pre><code>Training until validation scores don't improve for 20 rounds
Early stopping, best iteration is:
[147]	valid_0's auc: 0.860844	valid_1's auc: 0.778985
Training until validation scores don't improve for 20 rounds
Early stopping, best iteration is:
[99]	valid_0's auc: 0.836905	valid_1's auc: 0.777066
Training until validation scores don't improve for 20 rounds
Early stopping, best iteration is:
[121]	valid_0's auc: 0.846901	valid_1's auc: 0.777927
Training until validation scores don't improve for 20 rounds
Early stopping, best iteration is:
[118]	valid_0's auc: 0.846341	valid_1's auc: 0.778487
Training until validation scores don't improve for 20 rounds
Early stopping, best iteration is:
[114]	valid_0's auc: 0.845653	valid_1's auc: 0.776624
valid auc: 0.779 +/- 0.001
evaluate cost time 0 hours 1 minutes 57 seconds
</code></pre>
<h2 id="model-2-set-class-weight"><a class="markdownIt-Anchor" href="#model-2-set-class-weight"></a> model 2: Set class weight</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model2 = clone(model) <span class="comment"># Construct a new unfitted estimator with the same parameters.</span></span><br><span class="line">model2.set_params(class_weight=<span class="string">&#x27;balanced&#x27;</span>)</span><br><span class="line"></span><br><span class="line">score = evaluate(model2, train_dummies, y_train, params=fit_params)</span><br></pre></td></tr></table></figure>
<pre><code>Training until validation scores don't improve for 20 rounds
Early stopping, best iteration is:
[122]	valid_0's auc: 0.843105	valid_1's auc: 0.780157
Training until validation scores don't improve for 20 rounds
Early stopping, best iteration is:
[95]	valid_0's auc: 0.831016	valid_1's auc: 0.780049
Training until validation scores don't improve for 20 rounds
Early stopping, best iteration is:
[107]	valid_0's auc: 0.835709	valid_1's auc: 0.779769
Training until validation scores don't improve for 20 rounds
Early stopping, best iteration is:
[159]	valid_0's auc: 0.856821	valid_1's auc: 0.781057
Training until validation scores don't improve for 20 rounds
Early stopping, best iteration is:
[138]	valid_0's auc: 0.848312	valid_1's auc: 0.779905
valid auc: 0.780 +/- 0.002
evaluate cost time 0 hours 2 minutes 20 seconds
</code></pre>
<p>设置 <code>is_unbalance=True</code> 后，模型有所改善。</p>
<h2 id="model-3-smote"><a class="markdownIt-Anchor" href="#model-3-smote"></a> model 3: SMOTE</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> imblearn.over_sampling <span class="keyword">import</span> SMOTE </span><br><span class="line"><span class="keyword">import</span> imblearn</span><br><span class="line"></span><br><span class="line">X_balanced, y_balanced = SMOTE(random_state=SEED).fit_resample(train_dummies, y_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;balanced train data shape:&#x27;</span>, X_balanced.shape)</span><br><span class="line"></span><br><span class="line">score = evaluate(clone(model), X_balanced, y_balanced, params=fit_params)</span><br></pre></td></tr></table></figure>
<pre><code>balanced train data shape: (423998, 990)
Training until validation scores don't improve for 20 rounds
Early stopping, best iteration is:
[64]	valid_0's auc: 0.726936	valid_1's auc: 0.7216
Training until validation scores don't improve for 20 rounds
Early stopping, best iteration is:
[138]	valid_0's auc: 0.834743	valid_1's auc: 0.780546
Training until validation scores don't improve for 20 rounds
Early stopping, best iteration is:
[167]	valid_0's auc: 0.849441	valid_1's auc: 0.782093
Training until validation scores don't improve for 20 rounds
Early stopping, best iteration is:
[140]	valid_0's auc: 0.834219	valid_1's auc: 0.780796
Training until validation scores don't improve for 20 rounds
Early stopping, best iteration is:
[166]	valid_0's auc: 0.848353	valid_1's auc: 0.780799
valid auc: 0.976 +/- 0.048
evaluate cost time 0 hours 5 minutes 46 seconds
</code></pre>
<h2 id="model-4-ensemble-method"><a class="markdownIt-Anchor" href="#model-4-ensemble-method"></a> model 4: Ensemble method</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> imblearn.ensemble <span class="keyword">import</span> BalancedRandomForestClassifier</span><br><span class="line"></span><br><span class="line">model4 = BalancedRandomForestClassifier(</span><br><span class="line">    n_estimators=<span class="number">100</span>, </span><br><span class="line">    max_depth=<span class="number">5</span>,</span><br><span class="line">    random_state=SEED,</span><br><span class="line">    verbose=<span class="number">1</span></span><br><span class="line">)</span><br><span class="line">score = evaluate(model4, train_dummies, y_train)</span><br></pre></td></tr></table></figure>
<pre><code>[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    7.3s
[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s
[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    7.2s
[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s
[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    7.2s
[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s
[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    7.3s
[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s
[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    7.1s
[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s


valid auc: 0.738 +/- 0.002
evaluate cost time 0 hours 1 minutes 21 seconds
</code></pre>
<h2 id="model-5-focalloss"><a class="markdownIt-Anchor" href="#model-5-focalloss"></a> model 5: FocalLoss</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> focal_loss <span class="keyword">import</span> BinaryFocalLoss <span class="comment"># self-define loss function</span></span><br><span class="line"></span><br><span class="line">focalloss = BinaryFocalLoss(alpha=<span class="number">0.9</span>, gamma=<span class="number">0.05</span>)</span><br><span class="line">model5 = clone(model) </span><br><span class="line">model5.set_params(objective = focalloss.objective)</span><br><span class="line">fit_params[<span class="string">&#x27;eval_metric&#x27;</span>] = focalloss.evaluate</span><br><span class="line"></span><br><span class="line">score = evaluate(model5, train_dummies, y_train, params=fit_params)</span><br></pre></td></tr></table></figure>
<pre><code>[LightGBM] [Info] Using self-defined objective function
Training until validation scores don't improve for 20 rounds
Early stopping, best iteration is:
[116]	valid_0's auc: 0.840709	valid_0's focal_loss: 0.0792912	valid_1's auc: 0.780966	valid_1's focal_loss: 0.0886921
[LightGBM] [Info] Using self-defined objective function
Training until validation scores don't improve for 20 rounds
Early stopping, best iteration is:
[87]	valid_0's auc: 0.82691	valid_0's focal_loss: 0.0816416	valid_1's auc: 0.779874	valid_1's focal_loss: 0.0888508
[LightGBM] [Info] Using self-defined objective function
Training until validation scores don't improve for 20 rounds
Early stopping, best iteration is:
[101]	valid_0's auc: 0.832985	valid_0's focal_loss: 0.0805644	valid_1's auc: 0.779294	valid_1's focal_loss: 0.0889485
[LightGBM] [Info] Using self-defined objective function
Training until validation scores don't improve for 20 rounds
Early stopping, best iteration is:
[87]	valid_0's auc: 0.827538	valid_0's focal_loss: 0.0816012	valid_1's auc: 0.78189	valid_1's focal_loss: 0.0885146
[LightGBM] [Info] Using self-defined objective function
Training until validation scores don't improve for 20 rounds
Early stopping, best iteration is:
[119]	valid_0's auc: 0.840904	valid_0's focal_loss: 0.0792486	valid_1's auc: 0.781548	valid_1's focal_loss: 0.0886565
valid auc: nan +/- nan
evaluate cost time 0 hours 2 minutes 16 seconds
</code></pre>
<p>自定义FocalLoss损失函数后，表现不错</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">del</span> train_dummies, valid_dummies</span><br><span class="line">gc.collect()</span><br></pre></td></tr></table></figure>
<h1 id="step-4-hyperparameter-tuning"><a class="markdownIt-Anchor" href="#step-4-hyperparameter-tuning"></a> Step 4: Hyperparameter Tuning</h1>
<p>超参数调优算法主要有网格搜索(Grid Search)，随机搜索(Randomized Search)和贝叶斯优化(Bayesian Optimization)，本文采用贝叶斯优化。</p>
<p>本章准备使用LightGBM原生接口，需要创建 lightgbm 原生数据集</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Create Dataset object for lightgbm</span></span><br><span class="line">dtrain = lgb.Dataset(</span><br><span class="line">    X_train, label=y_train, </span><br><span class="line">    free_raw_data=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># In LightGBM, the validation data should be aligned with training data.</span></span><br><span class="line"><span class="comment"># if you want to re-use data, remember to set free_raw_data=False</span></span><br><span class="line">dvalid = lgb.Dataset(</span><br><span class="line">    X_valid, label=y_valid, </span><br><span class="line">    reference=dtrain, </span><br><span class="line">    free_raw_data=<span class="literal">True</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h2 id="超参数和目标函数设置"><a class="markdownIt-Anchor" href="#超参数和目标函数设置"></a> 超参数和目标函数设置</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Here we use Optuna</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># define the search space and the objecive function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">objective</span>(<span class="params">trial</span>):</span></span><br><span class="line">    <span class="comment"># LightGBM can use a dictionary to set Parameters.</span></span><br><span class="line">    params = <span class="built_in">dict</span>(</span><br><span class="line">        boosting_type = <span class="string">&#x27;gbdt&#x27;</span>,</span><br><span class="line">        objective = <span class="string">&#x27;binary&#x27;</span>,</span><br><span class="line">        metric = <span class="string">&#x27;auc&#x27;</span>,</span><br><span class="line">        is_unbalance = <span class="literal">True</span>,</span><br><span class="line">        num_boost_round = trial.suggest_int(<span class="string">&quot;num_boost_round&quot;</span>, <span class="number">50</span>, <span class="number">2000</span>, step=<span class="number">50</span>),</span><br><span class="line">        learning_rate = trial.suggest_float(<span class="string">&quot;learning_rate&quot;</span>, <span class="number">1e-4</span>, <span class="number">10</span>, log=<span class="literal">True</span>), </span><br><span class="line">        max_depth = trial.suggest_int(<span class="string">&quot;max_depth&quot;</span>, <span class="number">2</span>, <span class="number">10</span>),  </span><br><span class="line">        feature_fraction = trial.suggest_float(<span class="string">&quot;feature_fraction&quot;</span>, <span class="number">0.2</span>, <span class="number">1.0</span>), </span><br><span class="line">        bagging_fraction = trial.suggest_float(<span class="string">&quot;bagging_fraction&quot;</span>, <span class="number">0.2</span>, <span class="number">1.0</span>),  </span><br><span class="line">        bagging_freq = <span class="number">5</span>,</span><br><span class="line">        lambda_l1 = trial.suggest_float(<span class="string">&quot;lambda_l1&quot;</span>, <span class="number">1e-4</span>, <span class="number">1e2</span>, log=<span class="literal">True</span>),  </span><br><span class="line">        lambda_l2 = trial.suggest_float(<span class="string">&quot;lambda_l2&quot;</span>, <span class="number">1e-4</span>, <span class="number">1e2</span>, log=<span class="literal">True</span>),</span><br><span class="line">        random_state = SEED,</span><br><span class="line">        verbosity = -<span class="number">1</span></span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Perform the cross-validation with given parameters.</span></span><br><span class="line">    eval_results = lgb.cv(</span><br><span class="line">        params, </span><br><span class="line">        dtrain, </span><br><span class="line">        nfold = <span class="number">5</span>,</span><br><span class="line">        shuffle = <span class="literal">True</span>,</span><br><span class="line">        feature_name = feature_name,</span><br><span class="line">        categorical_feature = categorical_feature,</span><br><span class="line">        callbacks=[lgb.early_stopping(<span class="number">20</span>)]</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> eval_results[<span class="string">&#x27;valid auc-mean&#x27;</span>][-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<h2 id="贝叶斯优化"><a class="markdownIt-Anchor" href="#贝叶斯优化"></a> 贝叶斯优化</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Bayesian optimization</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># create a study object.</span></span><br><span class="line">study = optuna.create_study(</span><br><span class="line">    study_name = <span class="string">&#x27;lightgbm-study&#x27;</span>,  <span class="comment"># Unique identifier of the study.</span></span><br><span class="line">    direction = <span class="string">&#x27;maximize&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Invoke optimization of the objective function.</span></span><br><span class="line">study.optimize(</span><br><span class="line">    objective, </span><br><span class="line">    n_trials = <span class="number">100</span>, </span><br><span class="line">    timeout = <span class="number">7200</span>,</span><br><span class="line">    gc_after_trial = <span class="literal">True</span>,</span><br><span class="line">    show_progress_bar = <span class="literal">True</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">joblib.dump(study, path + <span class="string">&quot;lightgbm-study.pkl&quot;</span>)</span><br><span class="line"></span><br><span class="line">study = joblib.load(path + <span class="string">&quot;lightgbm-study.pkl&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Best trial until now:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; Value: &quot;</span>, study.best_trial.value)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; Params: &quot;</span>)</span><br><span class="line"><span class="keyword">for</span> key, value <span class="keyword">in</span> study.best_trial.params.items():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;    <span class="subst">&#123;key&#125;</span>: <span class="subst">&#123;value&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Best trial until now:
 Value:  0.785777090367696
 Params: 
    num_boost_round: 1000
    learning_rate: 0.029182324488925142
    max_depth: 8
    feature_fraction: 0.902981862669475
    bagging_fraction: 0.9853966386414182
    lambda_l1: 73.55650874339202
    lambda_l2: 6.572289325673235
</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Continue to study</span></span><br><span class="line">study.optimize(</span><br><span class="line">    objective, </span><br><span class="line">    n_trials = <span class="number">100</span>, </span><br><span class="line">    timeout = <span class="number">7200</span>,</span><br><span class="line">    gc_after_trial = <span class="literal">True</span>,</span><br><span class="line">    show_progress_bar = <span class="literal">True</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Number of finished trials: &quot;</span>, <span class="built_in">len</span>(study.trials))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Best trial until now:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; Best value: &quot;</span>, study.best_trial.value)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; Best params: &quot;</span>)</span><br><span class="line"><span class="keyword">for</span> key, value <span class="keyword">in</span> study.best_trial.params.items():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;    <span class="subst">&#123;key&#125;</span>: <span class="subst">&#123;value&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Number of finished trials:  135
Best trial until now:
 Best value:  0.7865747325768904
 Best params: 
    num_boost_round: 1300
    learning_rate: 0.015480784915810246
    max_depth: 8
    feature_fraction: 0.3519165350962246
    bagging_fraction: 0.9999568798413535
    lambda_l1: 65.08840723355036
    lambda_l2: 15.024421566966097
</code></pre>
<h2 id="可视化"><a class="markdownIt-Anchor" href="#可视化"></a> 可视化</h2>
<p>绘制优化过程曲线</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">optuna.visualization.plot_optimization_history(study)</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/feature_engineering_with_python/ML_output_42_1.png" alt="" /></p>
<p>绘制study目标值的edf</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">optuna.visualization.plot_edf(study)</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/feature_engineering_with_python/ML_output_44_0.png" alt="" /></p>
<h1 id="step-5-training"><a class="markdownIt-Anchor" href="#step-5-training"></a> Step 5: Training</h1>
<h2 id="训练"><a class="markdownIt-Anchor" href="#训练"></a> 训练</h2>
<p>本节准备使用LightGBM原生接口，需要创建 lightgbm 原生数据集</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Create Dataset object for lightgbm</span></span><br><span class="line">dtrain = lgb.Dataset(</span><br><span class="line">    X_train, label=y_train, </span><br><span class="line">    free_raw_data=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># In LightGBM, the validation data should be aligned with training data.</span></span><br><span class="line"><span class="comment"># if you want to re-use data, remember to set free_raw_data=False</span></span><br><span class="line">dvalid = lgb.Dataset(</span><br><span class="line">    X_valid, label=y_valid, </span><br><span class="line">    reference=dtrain, </span><br><span class="line">    free_raw_data=<span class="literal">True</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Starting training...&#x27;</span>)</span><br><span class="line"></span><br><span class="line">best_params = <span class="built_in">dict</span>(</span><br><span class="line">    boosting_type = <span class="string">&#x27;gbdt&#x27;</span>,</span><br><span class="line">    objective = <span class="string">&#x27;binary&#x27;</span>,</span><br><span class="line">    metric = <span class="string">&#x27;auc&#x27;</span>,</span><br><span class="line">    is_unbalance = <span class="literal">True</span>,</span><br><span class="line">    num_boost_round = <span class="number">1300</span>,</span><br><span class="line">    learning_rate = <span class="number">0.015480784915810246</span>,</span><br><span class="line">    max_depth = <span class="number">8</span>,</span><br><span class="line">    feature_fraction = <span class="number">0.3519165350962246</span>,</span><br><span class="line">    bagging_fraction = <span class="number">0.9999568798413535</span>,</span><br><span class="line">    lambda_l1 = <span class="number">65.08840723355036</span>,</span><br><span class="line">    lambda_l2 = <span class="number">15.024421566966097</span>,</span><br><span class="line">    subsample_freq = <span class="number">5</span>,</span><br><span class="line">    random_state = SEED,</span><br><span class="line">    verbosity = <span class="number">0</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">eval_results = &#123;&#125; <span class="comment"># to record eval results for plotting</span></span><br><span class="line">callbacks = [</span><br><span class="line">    lgb.log_evaluation(period=<span class="number">100</span>), </span><br><span class="line">    lgb.early_stopping(stopping_rounds=<span class="number">20</span>),</span><br><span class="line">    lgb.record_evaluation(eval_results)</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training</span></span><br><span class="line">bst = lgb.train(</span><br><span class="line">    best_params, </span><br><span class="line">    dtrain, </span><br><span class="line">    feature_name = feature_name, </span><br><span class="line">    categorical_feature = categorical_feature,</span><br><span class="line">    valid_sets = [dtrain, dvalid],</span><br><span class="line">    callbacks = callbacks</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<pre><code>Starting training...
[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth &gt; num_leaves. (num_leaves=31).
[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth &gt; num_leaves. (num_leaves=31).
[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth &gt; num_leaves. (num_leaves=31).
[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth &gt; num_leaves. (num_leaves=31).
[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth &gt; num_leaves. (num_leaves=31).
Training until validation scores don't improve for 20 rounds
[100]	training's auc: 0.77831	valid_1's auc: 0.760952
[200]	training's auc: 0.793115	valid_1's auc: 0.770076
[300]	training's auc: 0.803729	valid_1's auc: 0.775631
[400]	training's auc: 0.811797	valid_1's auc: 0.778893
[500]	training's auc: 0.818789	valid_1's auc: 0.78126
[600]	training's auc: 0.825071	valid_1's auc: 0.782986
[700]	training's auc: 0.830958	valid_1's auc: 0.784242
[800]	training's auc: 0.836567	valid_1's auc: 0.785216
[900]	training's auc: 0.841761	valid_1's auc: 0.785837
[1000]	training's auc: 0.846603	valid_1's auc: 0.786335
[1100]	training's auc: 0.851281	valid_1's auc: 0.786744
Early stopping, best iteration is:
[1118]	training's auc: 0.852112	valid_1's auc: 0.786804
</code></pre>
<h2 id="可视化-2"><a class="markdownIt-Anchor" href="#可视化-2"></a> 可视化</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Plotting metrics recorded during training</span></span><br><span class="line">ax = lgb.plot_metric(eval_results, metric=<span class="string">&#x27;auc&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/feature_engineering_with_python/ML_output_51_0.png" alt="" /><br />
​</p>
<h1 id="step-6-evaluating"><a class="markdownIt-Anchor" href="#step-6-evaluating"></a> Step 6: Evaluating</h1>
<h2 id="模型得分"><a class="markdownIt-Anchor" href="#模型得分"></a> 模型得分</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_adjusted_prediction</span>(<span class="params">y_score, threshold=<span class="number">0.5</span></span>):</span></span><br><span class="line">    y_pred = y_score.copy()</span><br><span class="line">    y_pred[y_score&gt;=threshold] = <span class="number">1</span></span><br><span class="line">    y_pred[y_score&lt; threshold] = <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classification_report</span>(<span class="params">model, X, y</span>):</span></span><br><span class="line">    <span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> balanced_accuracy_score</span><br><span class="line">    report = &#123;&#125;</span><br><span class="line">    y_true = y</span><br><span class="line">    y_score = model.predict(X) </span><br><span class="line">    <span class="keyword">if</span> y_score.ndim &gt;= <span class="number">2</span>:</span><br><span class="line">        y_pred = np.argmax(y_score)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        y_pred = (y_score &gt; <span class="number">0.5</span>).astype(<span class="built_in">int</span>)</span><br><span class="line">    fpr, tpr, thresholds = roc_curve(y_true, y_score) </span><br><span class="line">    </span><br><span class="line">    idx = (tpr - fpr).argmax()</span><br><span class="line">    adjusted_threshold = thresholds[idx]</span><br><span class="line">    adjusted_y_pred = (y_score &gt; adjusted_threshold).astype(<span class="built_in">int</span>) </span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&#x27;y_pred&#x27;</span>: y_pred,</span><br><span class="line">        <span class="string">&#x27;y_score&#x27;</span>: y_score,</span><br><span class="line">        <span class="string">&#x27;fpr&#x27;</span>: fpr,</span><br><span class="line">        <span class="string">&#x27;tpr&#x27;</span>: tpr, </span><br><span class="line">        <span class="string">&#x27;thresholds&#x27;</span>: thresholds,</span><br><span class="line">        <span class="string">&#x27;ks&#x27;</span>: (tpr - fpr).<span class="built_in">max</span>(),</span><br><span class="line">        <span class="string">&#x27;auc&#x27;</span>: roc_auc_score(y_true, y_score),</span><br><span class="line">        <span class="string">&#x27;accuracy&#x27;</span>: accuracy_score(y_true, y_pred),</span><br><span class="line">        <span class="string">&#x27;balanced_accuracy_score&#x27;</span>: balanced_accuracy_score(y_true, y_pred),</span><br><span class="line">        <span class="string">&#x27;precision&#x27;</span>: precision_score(y_true, y_pred),</span><br><span class="line">        <span class="string">&#x27;recall&#x27;</span>: recall_score(y_true, y_pred),</span><br><span class="line">        <span class="string">&#x27;f1-score&#x27;</span>: fbeta_score(y_true, y_pred, beta=<span class="number">1</span>),</span><br><span class="line">        <span class="string">&#x27;adjusted_threshold&#x27;</span>: adjusted_threshold,</span><br><span class="line">        <span class="string">&#x27;adjusted_accuracy&#x27;</span>: accuracy_score(y_true, adjusted_y_pred)</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment"># the model performance</span></span><br><span class="line">train_report = classification_report(bst, X_train, y_train)</span><br><span class="line">valid_report = classification_report(bst, X_valid, y_valid)</span><br><span class="line"><span class="keyword">for</span> label, stats <span class="keyword">in</span> [(<span class="string">&#x27;train data&#x27;</span>, train_report), (<span class="string">&#x27;valid data&#x27;</span>, valid_report)]:</span><br><span class="line">    <span class="built_in">print</span>(label, <span class="string">&quot;:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(</span><br><span class="line">        <span class="string">f&quot;auc: <span class="subst">&#123;stats[<span class="string">&#x27;auc&#x27;</span>]:<span class="number">.5</span>f&#125;</span>&quot;</span>, </span><br><span class="line">        <span class="string">f&quot;accuracy: <span class="subst">&#123;stats[<span class="string">&#x27;accuracy&#x27;</span>]:<span class="number">.5</span>f&#125;</span>&quot;</span>, </span><br><span class="line">        <span class="string">f&quot;balanced_accuracy_score: <span class="subst">&#123;stats[<span class="string">&#x27;balanced_accuracy_score&#x27;</span>]:<span class="number">.5</span>f&#125;</span>&quot;</span>,</span><br><span class="line">        <span class="string">f&quot;adjusted_accuracy(threshold = <span class="subst">&#123;stats[<span class="string">&#x27;adjusted_threshold&#x27;</span>]:<span class="number">.4</span>f&#125;</span>): <span class="subst">&#123;stats[<span class="string">&#x27;adjusted_accuracy&#x27;</span>]:<span class="number">.5</span>f&#125;</span>&quot;</span>, </span><br><span class="line">        <span class="string">f&quot;recall: <span class="subst">&#123;stats[<span class="string">&#x27;recall&#x27;</span>]:<span class="number">.5</span>f&#125;</span>&quot;</span>, </span><br><span class="line">        sep = <span class="string">&#x27;\n\t&#x27;</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<pre><code>train data :
auc: 0.85211
	accuracy: 0.75527
	balanced_accuracy_score: 0.77060
	adjusted_accuracy(threshold = 0.4885): 0.74530
	recall: 0.78888
valid data :
auc: 0.78680
	accuracy: 0.73706
	balanced_accuracy_score: 0.71237
	adjusted_accuracy(threshold = 0.4526): 0.69454
	recall: 0.68293
</code></pre>
<h2 id="roc曲线"><a class="markdownIt-Anchor" href="#roc曲线"></a> ROC曲线</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Plot ROC curve</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_roc_curve</span>(<span class="params">fprs, tprs, labels</span>):</span></span><br><span class="line">    <span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.title(<span class="string">&#x27;Receiver Operating Characteristic&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;False Positive Rate&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;True Positive Rate&#x27;</span>)</span><br><span class="line">    plt.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>],<span class="string">&#x27;r--&#x27;</span>)</span><br><span class="line">    plt.xlim([<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">    plt.ylim([<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">    <span class="comment"># Plotting ROC and computing AUC scores</span></span><br><span class="line">    <span class="keyword">for</span> fpr, tpr, label <span class="keyword">in</span> <span class="built_in">zip</span>(fprs, tprs, labels):</span><br><span class="line">    	auc = metrics.auc(fpr, tpr)</span><br><span class="line">    	plt.plot(fpr, tpr, label = <span class="string">f&quot;<span class="subst">&#123;label&#125;</span> ROC(auc=<span class="subst">&#123;auc:<span class="number">.4</span>f&#125;</span>)&quot;</span>)</span><br><span class="line">    plt.legend(loc = <span class="string">&#x27;lower right&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plot_roc_curve(</span><br><span class="line">    fprs = (train_report[<span class="string">&#x27;fpr&#x27;</span>], valid_report[<span class="string">&#x27;fpr&#x27;</span>]),</span><br><span class="line">    tprs = (train_report[<span class="string">&#x27;tpr&#x27;</span>], valid_report[<span class="string">&#x27;tpr&#x27;</span>]),</span><br><span class="line">    labels = (<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;valid&#x27;</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/feature_engineering_with_python/ML_output_55_0.png" alt="" /><br />
​</p>
<h2 id="模型稳定性"><a class="markdownIt-Anchor" href="#模型稳定性"></a> 模型稳定性</h2>
<p>PSI(Population Stability Index)指标反映了实际分布(actual)与预期分布(expected)的差异。在建模中，我们常用来筛选特征变量、评估模型稳定性。其中，在建模时通常以训练样本(In the Sample, INS)作为预期分布，而验证样本在各分数段的分布通常作为实际分布。验证样本一般包括样本外(Out of Sample, OOS)和跨时间样本(Out of Time, OOT)。</p>
<blockquote>
<p>风控模型常用PSI衡量模型的稳定性。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calc_psi</span>(<span class="params">expected, actual, n_bins=<span class="number">10</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Calculate the PSI (Population Stability Index) for two vectors.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        expected: array-like, represents the expected distribution.</span></span><br><span class="line"><span class="string">        actual: array-like, represents the actual distribution.</span></span><br><span class="line"><span class="string">        bins: int, the number of bins to use in the histogram.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    float, the PSI value.</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># Calculate the expected frequencies in each bin</span></span><br><span class="line">    buckets, bins = pd.qcut(expected, n_bins, retbins=<span class="literal">True</span>, duplicates=<span class="string">&#x27;drop&#x27;</span>)</span><br><span class="line">    expected_freq = buckets.value_counts() </span><br><span class="line">    expected_freq = expected_freq / expected_freq.<span class="built_in">sum</span>()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Calculate the actual frequencies in each bin</span></span><br><span class="line">    bins = [-np.inf] + <span class="built_in">list</span>(bins)[<span class="number">1</span>: -<span class="number">1</span>] + [np.inf]</span><br><span class="line">    actual_freq = pd.cut(actual, bins).value_counts()</span><br><span class="line">    actual_freq = actual_freq / actual_freq.<span class="built_in">sum</span>()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Calculate PSI</span></span><br><span class="line">    psi = (actual_freq - expected_freq) * np.log(actual_freq / expected_freq)</span><br><span class="line">    <span class="keyword">return</span> psi.<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">psi = calc_psi(train_report[<span class="string">&#x27;y_score&#x27;</span>], valid_report[<span class="string">&#x27;y_score&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;PSI:&quot;</span>, psi)</span><br></pre></td></tr></table></figure>
<pre><code>PSI: 0.00019890720303521737
</code></pre>
<p>绘制实际分布与预期分布曲线</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">4</span>)) </span><br><span class="line">sns.kdeplot(x=train_report[<span class="string">&#x27;y_score&#x27;</span>], label=<span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">sns.kdeplot(x=valid_report[<span class="string">&#x27;y_score&#x27;</span>], label=<span class="string">&#x27;valid&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line">plt.title(label = <span class="string">&#x27;Frequency&#x27;</span>, loc =<span class="string">&#x27;center&#x27;</span>) </span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/feature_engineering_with_python/ML_output_59_1.png" alt="" /></p>
<p>验证集正负样本分布曲线</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">valid_pred = pd.DataFrame(&#123;<span class="string">&#x27;score&#x27;</span>: valid_report[<span class="string">&#x27;y_score&#x27;</span>], <span class="string">&#x27;target&#x27;</span>: y_valid&#125;)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">4</span>)) </span><br><span class="line">sns.kdeplot(data=valid_pred, x=<span class="string">&#x27;score&#x27;</span>, hue=<span class="string">&#x27;target&#x27;</span>, common_norm=<span class="literal">False</span>)</span><br><span class="line">plt.title(label = <span class="string">&#x27;Frequency&#x27;</span>, loc =<span class="string">&#x27;center&#x27;</span>) </span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/feature_engineering_with_python/ML_output_61_1.png" alt="" /></p>
<p>验证集正负样本累积分布</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">4</span>)) </span><br><span class="line">sns.kdeplot(data=valid_pred, x=<span class="string">&#x27;score&#x27;</span>, hue=<span class="string">&#x27;target&#x27;</span>, common_norm=<span class="literal">False</span>, cumulative=<span class="literal">True</span>)</span><br><span class="line">plt.title(label = <span class="string">&#x27;Cumulative&#x27;</span>, loc =<span class="string">&#x27;center&#x27;</span>) </span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/feature_engineering_with_python/ML_output_63_1.png" alt="" /></p>
<h1 id="step-7-show-feature-importance"><a class="markdownIt-Anchor" href="#step-7-show-feature-importance"></a> Step 7: Show feature importance</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">feature_imp = pd.Series(</span><br><span class="line">    bst.feature_importance(), </span><br><span class="line">    index=bst.feature_name()</span><br><span class="line">).sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(feature_imp.head(<span class="number">20</span>))</span><br><span class="line">feature_imp.to_excel(path + <span class="string">&#x27;feature_importance.xlsx&#x27;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>AMT_ANNUITY_/_AMT_CREDIT                           776
MODE(previous.PRODUCT_COMBINATION)                 590
MODE(installments.previous.PRODUCT_COMBINATION)    475
MODE(cash.previous.PRODUCT_COMBINATION)            355
EXT_SOURCE_2_+_EXT_SOURCE_3                        312
MAX(bureau.DAYS_CREDIT_ENDDATE)                    296
MAX(bureau.DAYS_CREDIT)                            281
MODE(previous.NAME_GOODS_CATEGORY)                 274
MODE(installments.previous.NAME_GOODS_CATEGORY)    270
MEAN(bureau.AMT_CREDIT_SUM_DEBT)                   252
MODE(cash.previous.NAME_GOODS_CATEGORY)            248
AMT_GOODS_PRICE_/_AMT_ANNUITY                      232
MEAN(previous.MEAN(cash.CNT_INSTALMENT_FUTURE))    210
frequency(CODE_GENDER_M)_by(EXT_SOURCE_1)          196
AMT_CREDIT_-_AMT_GOODS_PRICE                       195
SUM(bureau.AMT_CREDIT_SUM)                         192
SUM(bureau.AMT_CREDIT_MAX_OVERDUE)                 191
EXT_SOURCE_1_/_DAYS_BIRTH                          182
MAX(cash.previous.DAYS_LAST_DUE_1ST_VERSION)       178
DAYS_BIRTH_/_EXT_SOURCE_1                          176
dtype: int32
</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Plotting feature importances</span></span><br><span class="line">ax = lgb.plot_importance(bst, max_num_features=<span class="number">20</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/feature_engineering_with_python/ML_output_66_0.png" alt="" /></p>
<p>观察重点特征的分布</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X_valid.columns = X_valid.columns.<span class="built_in">str</span>.replace(<span class="string">&#x27; &#x27;</span>, <span class="string">&#x27;_&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> feature_imp.index[:<span class="number">10</span>]:</span><br><span class="line">    table = pd.DataFrame(&#123;col: X_valid[col], <span class="string">&#x27;label&#x27;</span>: y_valid&#125;)</span><br><span class="line">    <span class="keyword">if</span> table[col].dtype <span class="keyword">in</span> [np.float32, np.int32]:</span><br><span class="line">        table[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_binned&#x27;</span>] = pd.qcut(table[col], <span class="number">5</span>, duplicates=<span class="string">&#x27;drop&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        table[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_binned&#x27;</span>] = table[col] </span><br><span class="line">    <span class="built_in">print</span>(table.pivot_table(</span><br><span class="line">        index=<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_binned&#x27;</span>, </span><br><span class="line">        columns=<span class="string">&#x27;label&#x27;</span>,</span><br><span class="line">        values=<span class="string">&#x27;label&#x27;</span>,</span><br><span class="line">        aggfunc=<span class="string">&#x27;count&#x27;</span>)</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">if</span> table[<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_binned&#x27;</span>].nunique() &lt;= <span class="number">5</span>:</span><br><span class="line">        sns.violinplot(</span><br><span class="line">            data=table, </span><br><span class="line">            x=<span class="string">f&#x27;<span class="subst">&#123;col&#125;</span>_binned&#x27;</span>,</span><br><span class="line">            y=valid_report[<span class="string">&#x27;y_score&#x27;</span>],</span><br><span class="line">            hue=<span class="string">&#x27;label&#x27;</span>,</span><br><span class="line">            split=<span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line">        plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>label                                0     1
AMT_ANNUITY_/_AMT_CREDIT_binned             
(0.015799999999999998, 0.0332]   14353  1039
(0.0332, 0.0463]                 14392   974
(0.0463, 0.0512]                 13906  1499
(0.0512, 0.0682]                 13890  1450
(0.0682, 0.124]                  14146  1229
</code></pre>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/feature_engineering_with_python/ML_output_68_1.png" alt="" /></p>
<pre><code>label                                          0     1
MODE(previous.PRODUCT_COMBINATION)_binned             
Card Street                                 6497   729
Card X-Sell                                 3161   274
Cash                                       12431  1234
Cash Street: high                           2147   240
Cash Street: low                             918    81
Cash Street: middle                          910    91
Cash X-Sell: high                           1695   207
Cash X-Sell: low                            2944   169
Cash X-Sell: middle                         3851   323
POS household with interest                17801  1333
POS household without interest              3204   205
POS industry with interest                  4379   282
POS industry without interest                474    17
POS mobile with interest                    8690   875
POS mobile without interest                  685    54
POS other with interest                      816    73
POS others without interest                   84     4
label                                                   0     1
MODE(installments.previous.PRODUCT_COMBINATION)...             
Card Street                                          4039   472
Card X-Sell                                          5686   628
Cash Street: high                                    2265   259
Cash Street: low                                      903    77
Cash Street: middle                                  1300   128
Cash X-Sell: high                                    2132   251
Cash X-Sell: low                                     4010   193
Cash X-Sell: middle                                  5394   394
POS household with interest                         19706  1657
POS household without interest                       5942   412
POS industry with interest                           6274   424
POS industry without interest                         828    31
POS mobile with interest                             9593  1032
POS mobile without interest                          1086    97
POS other with interest                              1369   127
POS others without interest                           160     9
label                                               0     1
MODE(cash.previous.PRODUCT_COMBINATION)_binned             
Cash Street: high                                2695   340
Cash Street: low                                 1053    95
Cash Street: middle                              1554   171
Cash X-Sell: high                                2544   315
Cash X-Sell: low                                 4653   258
Cash X-Sell: middle                              6635   496
POS household with interest                     22600  1994
POS household without interest                   6767   494
POS industry with interest                       6970   493
POS industry without interest                     923    35
POS mobile with interest                        11399  1241
POS mobile without interest                      1219   112
POS other with interest                          1498   136
POS others without interest                       177    11
label                                   0     1
EXT_SOURCE_2_+_EXT_SOURCE_3_binned             
(0.00013999999999999993, 0.799]     12583  2793
(0.799, 0.987]                      13994  1381
(0.987, 1.132]                      14411   965
(1.132, 1.264]                      14688   687
(1.264, 1.681]                      15011   365
</code></pre>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/feature_engineering_with_python/ML_output_68_3.png" alt="" /></p>
<pre><code>label                                       0     1
MAX(bureau.DAYS_CREDIT_ENDDATE)_binned             
(-41875.001, 80.0]                      14445   941
(80.0, 823.0]                           14358  1014
(823.0, 983.0]                          13918  1453
(983.0, 1735.0]                         13997  1399
(1735.0, 31199.0]                       13969  1384
</code></pre>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/feature_engineering_with_python/ML_output_68_5.png" alt="" /></p>
<pre><code>label                               0     1
MAX(bureau.DAYS_CREDIT)_binned             
(-2922.001, -661.0]             14554   825
(-661.0, -327.0]                14371  1031
(-327.0, -273.0]                13949  1408
(-273.0, -134.0]                14068  1326
(-134.0, -1.0]                  13745  1601
</code></pre>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/feature_engineering_with_python/ML_output_68_7.png" alt="" /></p>
<pre><code>label                                          0     1
MODE(previous.NAME_GOODS_CATEGORY)_binned             
Additional Service                            10     0
Audio/Video                                 6458   469
Auto Accessories                             467    42
Clothing and Accessories                    1541    89
Computers                                   5827   482
Construction Materials                      1432   104
Consumer Electronics                        5977   422
Direct Sales                                  29     5
Education                                     13     1
Fitness                                       17     1
Furniture                                   2578   143
Gardening                                    129     5
Homewares                                    242    15
Insurance                                      0     0
Jewelry                                      247    24
Medical Supplies                             256    10
Medicine                                     112     7
Mobile                                      9794   935
Office Appliances                             50     2
Other                                         49     5
Photo / Cinema Equipment                     550    56
Sport and Leisure                             79    13
Tourism                                       78     3
Vehicles                                     140    12
Weapon                                         5     0
XNA                                        34607  3346
label                                                   0     1
MODE(installments.previous.NAME_GOODS_CATEGORY)...             
Additional Service                                      9     0
Animals                                                 1     0
Audio/Video                                          6092   497
Auto Accessories                                      347    51
Clothing and Accessories                             1604    88
Computers                                            6324   542
Construction Materials                               1571   121
Consumer Electronics                                 7279   562
Direct Sales                                           13     4
Education                                              14     1
Fitness                                                22     1
Furniture                                            3235   208
Gardening                                             175     7
Homewares                                             363    29
Insurance                                               0     0
Jewelry                                               238    29
Medical Supplies                                      400    17
Medicine                                              162     9
Mobile                                              10152  1046
Office Appliances                                      90     9
Other                                                 100     7
Photo / Cinema Equipment                             1115   103
Sport and Leisure                                     150    18
Tourism                                               106     4
Vehicles                                              261    28
Weapon                                                  6     0
XNA                                                 30858  2810
label                                        0     1
MEAN(bureau.AMT_CREDIT_SUM_DEBT)_binned             
(-220213.42299999998, 0.0]               16805   994
(0.0, 39052.254]                         12066   886
(39052.254, 49487.143]                   13928  1448
(49487.143, 148125.9]                    13904  1471
(148125.9, 43650000.0]                   13984  1392
</code></pre>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/feature_engineering_with_python/ML_output_68_9.png" alt="" /></p>
<h1 id="step-8-visualize-the-model"><a class="markdownIt-Anchor" href="#step-8-visualize-the-model"></a> Step 8: Visualize the model</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Plotting split value histogram</span></span><br><span class="line">ax = lgb.plot_split_value_histogram(bst, feature=<span class="string">&#x27;AMT_ANNUITY_/_AMT_CREDIT&#x27;</span>, bins=<span class="string">&#x27;auto&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/feature_engineering_with_python/ML_output_70_0.png" alt="" /></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Plotting 54th tree (one tree use categorical feature to split)</span></span><br><span class="line"><span class="comment"># ax = lgb.plot_tree(bst, tree_index=53, figsize=(15, 15), show_info=[&#x27;split_gain&#x27;])</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Plotting 54th tree with graphviz</span></span><br><span class="line"><span class="comment"># graph = lgb.create_tree_digraph(bst, tree_index=53, name=&#x27;Tree54&#x27;)</span></span><br><span class="line"><span class="comment"># graph.render(view=True)</span></span><br></pre></td></tr></table></figure>
<h1 id="step-9-model-persistence"><a class="markdownIt-Anchor" href="#step-9-model-persistence"></a> Step 9: Model persistence</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Save model to file</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Saving model...&#x27;</span>)</span><br><span class="line">bst.save_model(path + <span class="string">&#x27;lgb_model.txt&#x27;</span>)   </span><br></pre></td></tr></table></figure>
<pre><code>Saving model...

&lt;lightgbm.basic.Booster at 0x2c457d3a0&gt;
</code></pre>
<h1 id="step-10-predict"><a class="markdownIt-Anchor" href="#step-10-predict"></a> Step 10: Predict</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Perform predictions</span></span><br><span class="line"><span class="comment"># If early stopping is enabled during training, you can get predictions from the best iteration with bst.best_iteration.</span></span><br><span class="line">predictions = bst.predict(X_valid, num_iteration=bst.best_iteration)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Load a saved model to predict </span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Loading model to predict...&#x27;</span>)</span><br><span class="line">bst = lgb.Booster(model_file=path + <span class="string">&#x27;lgb_model.txt&#x27;</span>)</span><br><span class="line">predictions = bst.predict(X_valid)</span><br></pre></td></tr></table></figure>
<pre><code>Loading model to predict...
</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Save predictions</span></span><br><span class="line"><span class="comment"># predictions.to_csv(&#x27;valid_predictions.csv&#x27;, index=True)</span></span><br></pre></td></tr></table></figure>
<h1 id="appendices-focalloss"><a class="markdownIt-Anchor" href="#appendices-focalloss"></a> Appendices: FocalLoss</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> optimize, special</span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BinaryFocalLoss</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, gamma, alpha=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="comment"># 使用FocalLoss只需要设定以上两个参数,如果alpha=None,默认取值为1</span></span><br><span class="line">        self.alpha = alpha</span><br><span class="line">        self.gamma = gamma</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">at</span>(<span class="params">self, y</span>):</span></span><br><span class="line">        <span class="comment"># alpha 参数, 根据FL的定义函数,正样本权重为self.alpha,负样本权重为1 - self.alpha</span></span><br><span class="line">        <span class="keyword">if</span> self.alpha <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> np.ones_like(y)</span><br><span class="line">        <span class="keyword">return</span> np.where(y, self.alpha, <span class="number">1</span> - self.alpha)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pt</span>(<span class="params">self, y, p</span>):</span></span><br><span class="line">        <span class="comment"># pt和p的关系</span></span><br><span class="line">        p = np.clip(p, <span class="number">1e-15</span>, <span class="number">1</span> - <span class="number">1e-15</span>)</span><br><span class="line">        <span class="keyword">return</span> np.where(y, p, <span class="number">1</span> - p)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, y_true, y_pred</span>):</span></span><br><span class="line">        <span class="comment"># 即FL的计算公式</span></span><br><span class="line">        at = self.at(y_true)</span><br><span class="line">        pt = self.pt(y_true, y_pred)</span><br><span class="line">        <span class="keyword">return</span> -at * (<span class="number">1</span> - pt) ** self.gamma * np.log(pt)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">grad</span>(<span class="params">self, y_true, y_pred</span>):</span></span><br><span class="line">        <span class="comment"># 一阶导数</span></span><br><span class="line">        y = <span class="number">2</span> * y_true - <span class="number">1</span>  <span class="comment"># &#123;0, 1&#125; -&gt; &#123;-1, 1&#125;</span></span><br><span class="line">        at = self.at(y_true)</span><br><span class="line">        pt = self.pt(y_true, y_pred)</span><br><span class="line">        g = self.gamma</span><br><span class="line">        <span class="keyword">return</span> at * y * (<span class="number">1</span> - pt) ** g * (g * pt * np.log(pt) + pt - <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">hess</span>(<span class="params">self, y_true, y_pred</span>):</span></span><br><span class="line">        <span class="comment"># 二阶导数</span></span><br><span class="line">        y = <span class="number">2</span> * y_true - <span class="number">1</span>  <span class="comment"># &#123;0, 1&#125; -&gt; &#123;-1, 1&#125;</span></span><br><span class="line">        at = self.at(y_true)</span><br><span class="line">        pt = self.pt(y_true, y_pred)</span><br><span class="line">        g = self.gamma</span><br><span class="line"></span><br><span class="line">        u = at * y * (<span class="number">1</span> - pt) ** g</span><br><span class="line">        du = -at * y * g * (<span class="number">1</span> - pt) ** (g - <span class="number">1</span>)</span><br><span class="line">        v = g * pt * np.log(pt) + pt - <span class="number">1</span></span><br><span class="line">        dv = g * np.log(pt) + g + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> (du * v + u * dv) * y * (pt * (<span class="number">1</span> - pt))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_score</span>(<span class="params">self, y_true</span>):</span></span><br><span class="line">        <span class="comment"># 样本初始值寻找过程</span></span><br><span class="line">        res = optimize.minimize_scalar(</span><br><span class="line">            <span class="keyword">lambda</span> p: self(y_true, p).<span class="built_in">sum</span>(),</span><br><span class="line">            bounds=(<span class="number">0</span>, <span class="number">1</span>),</span><br><span class="line">            method=<span class="string">&#x27;bounded&#x27;</span></span><br><span class="line">        )</span><br><span class="line">        p = res.x</span><br><span class="line">        log_odds = np.log(p / (<span class="number">1</span> - p))</span><br><span class="line">        <span class="keyword">return</span> log_odds</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">objective</span>(<span class="params">self, y_true, y_pred</span>):</span></span><br><span class="line">        y = y_true</span><br><span class="line">        p = special.expit(y_pred)</span><br><span class="line">        <span class="keyword">return</span> self.grad(y, p), self.hess(y, p)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">evaluate</span>(<span class="params">self, y_true, y_pred</span>):</span></span><br><span class="line">        y = y_true</span><br><span class="line">        p = special.expit(y_pred)</span><br><span class="line">        is_higher_better = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;focal_loss&#x27;</span>, self(y, p).mean(), is_higher_better</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fobj</span>(<span class="params">self, preds, train_data</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;lightgbm&#x27;&#x27;&#x27;</span></span><br><span class="line">        y = train_data.get_label()</span><br><span class="line">        p = special.expit(preds)</span><br><span class="line">        <span class="keyword">return</span> self.grad(y, p), self.hess(y, p)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">feval</span>(<span class="params">self, preds, train_data</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;lightgbm&#x27;&#x27;&#x27;</span></span><br><span class="line">        y = train_data.get_label()</span><br><span class="line">        p = special.expit(preds)</span><br><span class="line">        is_higher_better = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;focal_loss&#x27;</span>, self(y, p).mean(), is_higher_better</span><br><span class="line">    </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SparseCategoricalFocalLoss</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><a class="post-meta__tags" href="/tags/python/">python</a></div><div class="post_share"><div class="social-share" data-image="/img/FeatureEngine.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/morty3.jpg" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/morty3.jpg" alt="Give me money!"/></a><div class="post-qr-code-desc">Give me money!</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/799016ae/" title="特征工程(V)--时间序列特征"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/FeatureEngine.png" onerror="onerror=null;src='/img/404_moon.png'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">特征工程(V)--时间序列特征</div></div></a></div><div class="next-post pull-right"><a href="/posts/425f9947/" title="特征工程(VII)--模型集成"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/FeatureEngine.png" onerror="onerror=null;src='/img/404_moon.png'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">特征工程(VII)--模型集成</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/90489eb7/" title="PySpark机器学习Demo"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/spark-install.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-05-17</div><div class="title">PySpark机器学习Demo</div></div></a></div><div><a href="/posts/75974533/" title="大数据手册(Spark)--PySpark MLlib"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/apache-spark-mllib.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-05-01</div><div class="title">大数据手册(Spark)--PySpark MLlib</div></div></a></div><div><a href="/posts/425f9947/" title="特征工程(VII)--模型集成"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/FeatureEngine.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-04-20</div><div class="title">特征工程(VII)--模型集成</div></div></a></div><div><a href="/posts/794d8498/" title="Python(Machine Learning)--超参数优化"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/Hyperparameter-Optimization.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-15</div><div class="title">Python(Machine Learning)--超参数优化</div></div></a></div><div><a href="/posts/c46d5dae/" title="Python(Machine Learning)--XGBoost"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/XGBoost-cover.svg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-28</div><div class="title">Python(Machine Learning)--XGBoost</div></div></a></div><div><a href="/posts/44910830/" title="Python(Machine Learning)--LightGBM"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/LightGBM_cover.svg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-25</div><div class="title">Python(Machine Learning)--LightGBM</div></div></a></div></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div><div id="comment-switch"><span class="first-comment">Gitalk</span><span class="switch-btn"></span><span class="second-comment">Waline</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div><div><div id="waline-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Tiny Lei</div><div class="author-info__description">每天进步一点点...</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">168</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">107</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">43</div></a></div><div class="card-info-social-icons is-center"><a class="social-icon" href="https://gitee.com/wilenwu" rel="external nofollow noreferrer" target="_blank" title="Gitee"><i class="iconfont icon-gitee"></i></a><a class="social-icon" href="https://github.com/wilenwu" rel="external nofollow noreferrer" target="_blank" title="Github"><i class="iconfont icon-github"></i></a><a class="social-icon" href="https://blog.csdn.net/qq_41518277" rel="external nofollow noreferrer" target="_blank" title="CSDN"><i class="iconfont icon-csdn"></i></a><a class="social-icon" href="/atom.xml" target="_blank" title="RSS"><i class="iconfont icon-rss"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">感谢访问本站，若喜欢请收藏^_^</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#step-1-imports-and-configuration"><span class="toc-number">1.</span> <span class="toc-text"> Step 1: Imports and Configuration</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#step-2-load-the-datasets"><span class="toc-number">2.</span> <span class="toc-text"> Step 2: Load the datasets</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#step-3-data-preprocessing"><span class="toc-number">3.</span> <span class="toc-text"> Step 3: Data preprocessing</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#split-data"><span class="toc-number">3.1.</span> <span class="toc-text"> Split data</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#model-1-use-default-parameters"><span class="toc-number">3.2.</span> <span class="toc-text"> model 1: Use default parameters</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#model-2-set-class-weight"><span class="toc-number">3.3.</span> <span class="toc-text"> model 2: Set class weight</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#model-3-smote"><span class="toc-number">3.4.</span> <span class="toc-text"> model 3: SMOTE</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#model-4-ensemble-method"><span class="toc-number">3.5.</span> <span class="toc-text"> model 4: Ensemble method</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#model-5-focalloss"><span class="toc-number">3.6.</span> <span class="toc-text"> model 5: FocalLoss</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#step-4-hyperparameter-tuning"><span class="toc-number">4.</span> <span class="toc-text"> Step 4: Hyperparameter Tuning</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B6%85%E5%8F%82%E6%95%B0%E5%92%8C%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0%E8%AE%BE%E7%BD%AE"><span class="toc-number">4.1.</span> <span class="toc-text"> 超参数和目标函数设置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96"><span class="toc-number">4.2.</span> <span class="toc-text"> 贝叶斯优化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="toc-number">4.3.</span> <span class="toc-text"> 可视化</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#step-5-training"><span class="toc-number">5.</span> <span class="toc-text"> Step 5: Training</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83"><span class="toc-number">5.1.</span> <span class="toc-text"> 训练</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%AF%E8%A7%86%E5%8C%96-2"><span class="toc-number">5.2.</span> <span class="toc-text"> 可视化</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#step-6-evaluating"><span class="toc-number">6.</span> <span class="toc-text"> Step 6: Evaluating</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%BE%97%E5%88%86"><span class="toc-number">6.1.</span> <span class="toc-text"> 模型得分</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#roc%E6%9B%B2%E7%BA%BF"><span class="toc-number">6.2.</span> <span class="toc-text"> ROC曲线</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E7%A8%B3%E5%AE%9A%E6%80%A7"><span class="toc-number">6.3.</span> <span class="toc-text"> 模型稳定性</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#step-7-show-feature-importance"><span class="toc-number">7.</span> <span class="toc-text"> Step 7: Show feature importance</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#step-8-visualize-the-model"><span class="toc-number">8.</span> <span class="toc-text"> Step 8: Visualize the model</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#step-9-model-persistence"><span class="toc-number">9.</span> <span class="toc-text"> Step 9: Model persistence</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#step-10-predict"><span class="toc-number">10.</span> <span class="toc-text"> Step 10: Predict</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#appendices-focalloss"><span class="toc-number">11.</span> <span class="toc-text"> Appendices: FocalLoss</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/a36576b2/" title="机器学习(VII)--强化学习"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/reinforcement_learning_cover.png" onerror="this.onerror=null;this.src='/img/404_moon.png'" alt="机器学习(VII)--强化学习"/></a><div class="content"><a class="title" href="/posts/a36576b2/" title="机器学习(VII)--强化学习">机器学习(VII)--强化学习</a><time datetime="2024-08-29T09:18:30.000Z" title="发表于 2024-08-29 17:18:30">2024-08-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/e05c1b59/" title="机器学习(VI)--半监督学习"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/semi-supervised-cover.png" onerror="this.onerror=null;this.src='/img/404_moon.png'" alt="机器学习(VI)--半监督学习"/></a><div class="content"><a class="title" href="/posts/e05c1b59/" title="机器学习(VI)--半监督学习">机器学习(VI)--半监督学习</a><time datetime="2024-08-04T03:29:00.000Z" title="发表于 2024-08-04 11:29:00">2024-08-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/1ebcf865/" title="机器学习(VIII)--概率图模型(二)条件随机场"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/ML-PGM.png" onerror="this.onerror=null;this.src='/img/404_moon.png'" alt="机器学习(VIII)--概率图模型(二)条件随机场"/></a><div class="content"><a class="title" href="/posts/1ebcf865/" title="机器学习(VIII)--概率图模型(二)条件随机场">机器学习(VIII)--概率图模型(二)条件随机场</a><time datetime="2024-07-31T06:08:45.000Z" title="发表于 2024-07-31 14:08:45">2024-07-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/69c08fe2/" title="机器学习(VIII)--概率图模型(一)隐马尔可夫模型"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/ML-PGM.png" onerror="this.onerror=null;this.src='/img/404_moon.png'" alt="机器学习(VIII)--概率图模型(一)隐马尔可夫模型"/></a><div class="content"><a class="title" href="/posts/69c08fe2/" title="机器学习(VIII)--概率图模型(一)隐马尔可夫模型">机器学习(VIII)--概率图模型(一)隐马尔可夫模型</a><time datetime="2024-07-29T06:30:00.000Z" title="发表于 2024-07-29 14:30:00">2024-07-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/4f81b9fa/" title="机器学习(V)--无监督学习(三)EM算法"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/ML-unsupervised-learning.png" onerror="this.onerror=null;this.src='/img/404_moon.png'" alt="机器学习(V)--无监督学习(三)EM算法"/></a><div class="content"><a class="title" href="/posts/4f81b9fa/" title="机器学习(V)--无监督学习(三)EM算法">机器学习(V)--无监督学习(三)EM算法</a><time datetime="2024-07-09T12:47:30.000Z" title="发表于 2024-07-09 20:47:30">2024-07-09</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2024 By Tiny Lei</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"><script>(() => {
  const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaid.length === 0) return
  const runMermaid = () => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'forest'

    Array.from($mermaid).forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
      const mermaidID = 'mermaid-' + index
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)

      const renderV10 = () => {
        renderFn.then(({svg}) => {
          mermaidSrc.insertAdjacentHTML('afterend', svg)
        })
      }

      const renderV9 = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      typeof renderFn === 'string' ? renderV9(renderFn) : renderV10()
    })
  }

  const loadMermaid = () => {
    window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
  }

  btf.addModeChange('mermaid', runMermaid)

  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script><script>function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk(Object.assign({
      clientID: '7c65134b48b13f306114',
      clientSecret: 'f049f68368a11925fdb69e57c64839eac94e13c1'',
      repo: 'gitalk-comments',
      owner: 'WilenWu',
      admin: ['WilenWu'],
      id: '1c03e1d54f3290a5a824223a8ad68eaf',
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    getCSS('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css')
    getScript('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.textContent= n
  }
}

if ('Gitalk' === 'Gitalk' || !true) {
  if (true) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script><script>function loadWaline () {
  function initWaline () {
    const waline = Waline.init(Object.assign({
      el: '#waline-wrap',
      serverURL: 'https://waline-comments-9etq63pcv-wilenwu.vercel.app',
      pageview: false,
      dark: 'html[data-theme="dark"]',
      path: window.location.pathname,
      comment: false,
    }, {"requiredMeta":["monsterid"]}))
  }

  if (typeof Waline === 'object') initWaline()
  else {
    getCSS('https://cdn.jsdelivr.net/npm/@waline/client/dist/waline.min.css').then(() => {
      getScript('https://cdn.jsdelivr.net/npm/@waline/client/dist/waline.min.js').then(initWaline)
    })
  }
}

if ('Gitalk' === 'Waline' || !true) {
  if (true) btf.loadComment(document.getElementById('waline-wrap'),loadWaline)
  else setTimeout(loadWaline, 0)
} else {
  function loadOtherComment () {
    loadWaline()
  }
}</script></div><script src="/js/custom.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><!-- hexo injector body_end start --><script async src="//at.alicdn.com/t/font_2032782_8d5kxvn09md.js"></script><!-- hexo injector body_end end --></body></html>