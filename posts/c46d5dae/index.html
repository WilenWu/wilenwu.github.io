<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Python(Machine Learning)--XGBoost | 雷小小</title><meta name="author" content="Tiny Lei"><meta name="copyright" content="Tiny Lei"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Quick Start XGBoost本质上还是一个GBDT，但是力争把速度和效率发挥到极致，所以叫 Extreme Gradient Boosting。XGBoost高效地实现了GBDT算法，并进行了算法和工程上的许多改进，被广泛应用在Kaggle竞赛及其他许多机器学习竞赛中，并取得了不错的成绩。 而在实际建模环节，XGBoost提供了Sklearn API和原生API两套调用方法。大部分时候">
<meta property="og:type" content="article">
<meta property="og:title" content="Python(Machine Learning)--XGBoost">
<meta property="og:url" content="https://www.tinylei.tech/posts/c46d5dae/index.html">
<meta property="og:site_name" content="雷小小">
<meta property="og:description" content="Quick Start XGBoost本质上还是一个GBDT，但是力争把速度和效率发挥到极致，所以叫 Extreme Gradient Boosting。XGBoost高效地实现了GBDT算法，并进行了算法和工程上的许多改进，被广泛应用在Kaggle竞赛及其他许多机器学习竞赛中，并取得了不错的成绩。 而在实际建模环节，XGBoost提供了Sklearn API和原生API两套调用方法。大部分时候">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://www.tinylei.tech/img/XGBoost-cover.svg">
<meta property="article:published_time" content="2024-03-28T14:42:00.000Z">
<meta property="article:modified_time" content="2024-08-11T13:19:26.707Z">
<meta property="article:author" content="Tiny Lei">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="python">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://www.tinylei.tech/img/XGBoost-cover.svg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://www.tinylei.tech/posts/c46d5dae/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="baidu-site-verification" content="code-7rymn5Bitx"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?654e7415ab55bed7c9c2bc6d665f03c5";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Python(Machine Learning)--XGBoost',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-08-11 21:19:26'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="//at.alicdn.com/t/font_2849223_xh1ftc8qym.css"><link rel="stylesheet" href="/css/link-card.css"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script src="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.0.0"><link rel="alternate" href="/atom.xml" title="雷小小" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">175</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">108</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">43</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/user-guide/"><i class="fa-fw fa fa-compass"></i><span> 用户指南</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fa-fw fa fa-book"></i><span> 文档</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/gallery/"><i class="fa-fw fa fa-images"></i><span> 图库</span></a></div><div class="menus_item"><a class="site-page" href="/ebook/"><i class="fa-fw fa fa-book-reader"></i><span> 电子书</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-star"></i><span> 收藏夹</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fa-fw fa-solid fa-circle-chevron-down"></i><span> 更多</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/about/"><i class="fa-fw fa fa-user"></i><span> 关于我</span></a></li><li><a class="site-page child" href="/analytics/"><i class="fa-fw fa fa-line-chart"></i><span> 文章统计</span></a></li><li><a class="site-page child" href="/log/"><i class="fa-fw fa fa-history"></i><span> 更新日志</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/XGBoost-cover.svg')"><nav id="nav"><span id="blog-info"><a href="/" title="雷小小"><img class="site-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/favicon.png"/><span class="site-name">雷小小</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/user-guide/"><i class="fa-fw fa fa-compass"></i><span> 用户指南</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fa-fw fa fa-book"></i><span> 文档</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/gallery/"><i class="fa-fw fa fa-images"></i><span> 图库</span></a></div><div class="menus_item"><a class="site-page" href="/ebook/"><i class="fa-fw fa fa-book-reader"></i><span> 电子书</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-star"></i><span> 收藏夹</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fa-fw fa-solid fa-circle-chevron-down"></i><span> 更多</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/about/"><i class="fa-fw fa fa-user"></i><span> 关于我</span></a></li><li><a class="site-page child" href="/analytics/"><i class="fa-fw fa fa-line-chart"></i><span> 文章统计</span></a></li><li><a class="site-page child" href="/log/"><i class="fa-fw fa fa-history"></i><span> 更新日志</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Python(Machine Learning)--XGBoost<a class="post-edit-link" href="https://gitee.com/WilenWu/myblog/edit/master/source/_posts/python/Python(Machine-Learning)--xgboost.md" rel="external nofollow noreferrer" title="编辑" target="_blank"><i class="fas fa-pencil-alt"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-03-28T14:42:00.000Z" title="发表于 2024-03-28 22:42:00">2024-03-28</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-08-11T13:19:26.707Z" title="更新于 2024-08-11 21:19:26">2024-08-11</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/python/">Python</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/python/machine-learning/">Machine Learning</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">5.5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>22分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Python(Machine Learning)--XGBoost"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="quick-start"><a class="markdownIt-Anchor" href="#quick-start"></a> Quick Start</h1>
<p>XGBoost本质上还是一个GBDT，但是力争把速度和效率发挥到极致，所以叫 Extreme Gradient Boosting。XGBoost高效地实现了GBDT算法，并进行了算法和工程上的许多改进，被广泛应用在Kaggle竞赛及其他许多机器学习竞赛中，并取得了不错的成绩。</p>
<p>而在实际建模环节，XGBoost提供了Sklearn API和原生API两套调用方法。大部分时候我们使用原生代码来运行xgboost，因为这套原生代码是完全为集成学习所设计的，不仅可以无缝使用交叉验证、默认输出指标为RMSE，还能够默认输出训练集上的结果帮我们监控模型。</p>
<ol>
<li>首先，原生代码必须使用XGBoost自定义的数据结构DMatrix，这一数据结构能够保证xgboost算法运行更快，并且能够自然迁移到GPU上运行。</li>
<li>当设置好数据结构后，我们需要以字典形式设置参数。XGBoost也可以接受像sklearn一样，将所有参数都写在训练所用的类当中，然而由于xgboost的参数列表过长、参数类型过多，直接将所有参数混写在训练模型的类中会显得代码冗长且混乱，因此我们往往会使用字典单独呈现参数。</li>
<li>准备好参数列表后，我们将使用xgboost中自带的方法<code>xgb.train</code>或<code>xgb.cv</code>进行训练，训练完毕后，我们可以使用<code>predict</code>方法对结果进行预测。虽然xgboost原生代码库所使用的数据结构是DMatrix，但在预测试输出的数据结构却是普通的数组，因此可以直接使用sklearn中的评估指标，或者python编写的评估指标进行评估。</li>
</ol>
<table>
<thead>
<tr>
<th>数据结构</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener external nofollow noreferrer" href="https://xgboost.readthedocs.io/en/stable/python/python_api.html#Core-Data-Structure"><code>xgboost.DMatrix</code></a></td>
<td>XGBoost数据集</td>
</tr>
<tr>
<td><code>xgboost.DataIter</code></td>
<td>迭代数据</td>
</tr>
<tr>
<td><code>xgboost.QuantileDMatrix</code></td>
<td>直接为hist方法生成分位数数据</td>
</tr>
<tr>
<td><code>xgboost.Booster</code></td>
<td>XGBoost中的返回的模型</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">xgboost.DMatrix(data, </span><br><span class="line">                label=<span class="literal">None</span>, </span><br><span class="line">                weight=<span class="literal">None</span>, </span><br><span class="line">                base_margin=<span class="literal">None</span>, </span><br><span class="line">                missing=<span class="literal">None</span>, </span><br><span class="line">                silent=<span class="literal">False</span>, </span><br><span class="line">                feature_names=<span class="literal">None</span>, </span><br><span class="line">                feature_types=<span class="literal">None</span>, </span><br><span class="line">                nthread=<span class="literal">None</span>, </span><br><span class="line">                group=<span class="literal">None</span>, </span><br><span class="line">                qid=<span class="literal">None</span>, </span><br><span class="line">                label_lower_bound=<span class="literal">None</span>, </span><br><span class="line">                label_upper_bound=<span class="literal">None</span>, </span><br><span class="line">                feature_weights=<span class="literal">None</span>, </span><br><span class="line">                enable_categorical=<span class="literal">False</span>, </span><br><span class="line">                data_split_mode=DataSplitMode.ROW)</span><br></pre></td></tr></table></figure>
<p>常用参数：</p>
<ul>
<li>data 内部数据集的数据源</li>
<li>label 数据标签</li>
<li>weight 每个样本的权重</li>
<li>feature_names 特征名称</li>
<li>feature_types 数据类型。如果设置 <code>enable_categorical=False</code>，字符“c”代表分类数据，字符 &quot;q&quot;代表数值型数据。</li>
<li>feature_weights - Set feature weights for column sampling.</li>
<li>enable_categorical 允许分类特征</li>
</ul>
<p>现在，我们来简单看看原生代码是如何实现的。</p>
<p><a href="/ipynb/classification_demo.html#XGBoost">Jupyter Notebook Demo</a></p>
<h2 id="step-1-load-the-dataset"><a class="markdownIt-Anchor" href="#step-1-load-the-dataset"></a> Step 1:  Load the dataset</h2>
<p>DMatrix会将特征矩阵与标签打包在同一个对象中，且一次只能转换一组数据。并且，我们无法通过索引或循环查看内部的内容，一旦数据被转换为DMatrix，就难以调用或修改了。</p>
<p>因此，数据预处理需要在转换为DMatrix之前做好。如果我们有划分训练集和测试集，则需要分别将训练集和测试集转换为DMatrix。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># load or create your dataset</span></span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">X, y = load_boston(return_X_y=<span class="literal">True</span>)</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># create DMatrix for xgboost</span></span><br><span class="line">dtrain = xgb.DMatrix(X_train, y_train)</span><br><span class="line">dtest = xgb.DMatrix(X_test, y_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># specify validations set to watch performance</span></span><br><span class="line">watchlist = [(dtest, <span class="string">&quot;eval&quot;</span>), (dtrain, <span class="string">&quot;train&quot;</span>)]</span><br></pre></td></tr></table></figure>
<p>对于表示分类要素的所有列。之后，用户可以告诉 XGBoost 启用使用分类数据进行训练。假设您正在使用 for 分类问题，请指定 参数：enable_categorical</p>
<p>XGBoost 可以直接支持分类特征，而不需要 one-hot 编码。传递分类数据最简单方法是使用 dataframe ，将数据类型指定为 category。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># We need to specify the data type of input  as category.</span></span><br><span class="line">X[<span class="string">&quot;cat_feature&quot;</span>].astype(<span class="string">&quot;category&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>之后通过指定参数 <code>enable_categorical=True</code> 来启用分类数据进行训练</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Specify `enable_categorical` to True</span></span><br><span class="line">dtrain = xgb.DMatrix(X_train, y_train, enable_categorical=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">booster = xgb.train(&#123;<span class="string">&quot;tree_method&quot;</span>: <span class="string">&quot;hist&quot;</span>, <span class="string">&quot;max_cat_to_onehot&quot;</span>: <span class="number">5</span>&#125;, Xy)</span><br><span class="line"><span class="comment"># Must use JSON for serialization, otherwise the information is lost</span></span><br><span class="line">booster.save_model(<span class="string">&quot;categorical-model.json&quot;</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Note: 在构建 DMatrix 前，先把分类特征转换成整数型。</p>
</blockquote>
<p>对于其他类型的输入，例如 numpy/cupy array，我们可以通过 <code>feature_types</code> 参数设置分类特征。“q” 或 “float” 代表数值型特征，“c”代表分类特征。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#  &quot;q&quot; is numerical feature, while &quot;c&quot; is categorical feature</span></span><br><span class="line">ft = [<span class="string">&quot;q&quot;</span>, <span class="string">&quot;c&quot;</span>, <span class="string">&quot;c&quot;</span>]</span><br><span class="line">dtrain = xgb.DMatrix(X_train, y_train, feature_types=ft, enable_categorical=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h2 id="step-2-setting-parameters"><a class="markdownIt-Anchor" href="#step-2-setting-parameters"></a> Step 2: Setting Parameters</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># specify parameters via map</span></span><br><span class="line">param = &#123;<span class="string">&#x27;booster&#x27;</span>: <span class="string">&#x27;dart&#x27;</span>,</span><br><span class="line">         <span class="string">&#x27;max_depth&#x27;</span>: <span class="number">5</span>, </span><br><span class="line">         <span class="string">&#x27;learning_rate&#x27;</span>: <span class="number">0.1</span>,</span><br><span class="line">         <span class="string">&#x27;objective&#x27;</span>: <span class="string">&#x27;binary:logistic&#x27;</span>,</span><br><span class="line">         <span class="string">&#x27;sample_type&#x27;</span>: <span class="string">&#x27;uniform&#x27;</span>,</span><br><span class="line">         <span class="string">&#x27;normalize_type&#x27;</span>: <span class="string">&#x27;tree&#x27;</span>,</span><br><span class="line">         <span class="string">&#x27;rate_drop&#x27;</span>: <span class="number">0.1</span>,</span><br><span class="line">         <span class="string">&#x27;skip_drop&#x27;</span>: <span class="number">0.5</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># You can also specify multiple eval metrics:</span></span><br><span class="line">params[<span class="string">&#x27;eval_metric&#x27;</span>] =  [<span class="string">&#x27;error&#x27;</span>, <span class="string">&#x27;rmse&#x27;</span>]</span><br></pre></td></tr></table></figure>
<h2 id="step-3-training"><a class="markdownIt-Anchor" href="#step-3-training"></a> Step 3: Training</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Training a model requires a parameter list and data set:</span></span><br><span class="line">evals_result = &#123;&#125;</span><br><span class="line">bst = xgb.train(params,</span><br><span class="line">                dtrain,</span><br><span class="line">                num_boost_round=<span class="number">20</span>,</span><br><span class="line">                evals=watchlist,</span><br><span class="line">                evals_result = evals_result，</span><br><span class="line">                early_stopping_rounds=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training with 5-fold CV:</span></span><br><span class="line">xgb.cv(params, dtrain, num_boost_round=<span class="number">20</span>, nfold=<span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<p>不难发现，XGBoost不需要实例化，<code>xgb.train</code>函数包揽了实例化和训练的功能，一行代码解决所有问题。</p>
<h2 id="step-4-save-and-load-model"><a class="markdownIt-Anchor" href="#step-4-save-and-load-model"></a> Step 4: Save and load model</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Save model</span></span><br><span class="line">bst.save_model(<span class="string">&quot;model.json&quot;</span>)</span><br><span class="line"><span class="comment"># load model</span></span><br><span class="line">bst = xgb.Booster(model_file=<span class="string">&quot;model.json&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># alternatively, you can pickle the booster</span></span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;model.pkl&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> fout:</span><br><span class="line">    pickle.dump(bst, fout)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;model.pkl&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> fin:</span><br><span class="line">    bst = pickle.load(fin)</span><br></pre></td></tr></table></figure>
<p>XGBoost在Booster对象中有一个名为<code>dump_model</code>的函数，它允许以<code>text</code>、<code>json</code>或<code>dot</code>（graphviz）等可读格式导出模型。它的主要用于模型解释或可视化，不应该重新加载回XGBoost。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># dump model</span></span><br><span class="line">bst.dump_model(<span class="string">&quot;dump.raw.txt&quot;</span>)</span><br><span class="line"><span class="comment"># dump model with feature map</span></span><br><span class="line">bst.dump_model(<span class="string">&quot;dump.nice.txt&quot;</span>, os.path.join(DEMO_DIR, <span class="string">&quot;data/featmap.txt&quot;</span>))</span><br></pre></td></tr></table></figure>
<h2 id="step-5-predict"><a class="markdownIt-Anchor" href="#step-5-predict"></a> Step 5:  Predict</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># run prediction</span></span><br><span class="line">y_pred = bst.predict(dtest)</span><br><span class="line">y_true = dtest.get_label()</span><br><span class="line"></span><br><span class="line"><span class="comment"># If early stopping is enabled during training, you can get predictions from the best iteration with bst.best_iteration:</span></span><br><span class="line">y_pred = bst.predict(dtest, iteration_range=(<span class="number">0</span>, bst.best_iteration + <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<h2 id="step-6-evaluating"><a class="markdownIt-Anchor" href="#step-6-evaluating"></a> Step 6:  Evaluating</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metric <span class="keyword">import</span> mean_squared_error</span><br><span class="line">rmse_test = mean_squared_error(y_true, y_pred) ** <span class="number">0.5</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;The RMSE of prediction is: <span class="subst">&#123;rmse_test&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h1 id="参数"><a class="markdownIt-Anchor" href="#参数"></a> 参数</h1>
<p>xgboost将参数分为了两大部分，一部分可以通过params进行设置，另一部分则需要在方法<code>xgb.train</code>或者<code>xgb.cv</code>中进行设置。遗憾的是，xgboost并没有明确对参数分割的条件和理由，但一般来说，除了迭代次数和提前停止这两个关键元素，其他参数基本都被设置在<code>params</code>当中。如果在实际运行过程中，出现了警告或报错，则根据实际情况进行调整。</p>
<h2 id="一般参数"><a class="markdownIt-Anchor" href="#一般参数"></a> 一般参数</h2>
<ul>
<li><code>booster</code>：指定算法类型。default= <code>gbtree</code> 可以是gbtree、gblinear或dart。gbtree和dart使用基于树的模型，而gblinear使用线性函数。</li>
<li><code>device</code>：学习设备。default = cpu</li>
<li><code>nthread</code>：如果未设置，默认为最大可用线程数。</li>
<li><code>seed</code>：随机种子。</li>
<li><code>verbosity</code>：打印消息的详细性。有效值为0（静音）、1（警告）、2（信息）和3（调试），default=1。可以使用 <code>xgboost.config_context()</code> 在全局范围内设置。</li>
<li><code>num_parallel_tree</code> 每次迭代期间构建的并行树的数量。此选项用于支持增强的随机森林。default=1</li>
<li><code>multi_strategy</code> 用于训练多目标模型的策略，包括多目标回归和多类分类。default= <code>one_output_per_tree</code>
<ul>
<li><code>one_output_per_tree</code>：每个目标一个模型。</li>
<li><code>multi_output_tree</code>：使用多目标树。</li>
</ul>
</li>
</ul>
<h2 id="样本处理参数"><a class="markdownIt-Anchor" href="#样本处理参数"></a> 样本处理参数</h2>
<ul>
<li><code>scale_pos_weight</code> 控制正负样本的权重平衡，典型值：<code>sum(negative instances)/sum(positive instances)</code> 。default=1</li>
</ul>
<h2 id="特征处理参数"><a class="markdownIt-Anchor" href="#特征处理参数"></a> 特征处理参数</h2>
<ul>
<li><code>max_cat_to_onehot</code> 决定XGBoost是否使用one-hot编码的阈值。当类别数量小于阈值时，则选择one-hot编码，否则类别将被划分为子节点。</li>
<li><code>max_cat_threshold</code>  每一次分裂的最大类别数</li>
<li><code>max_bin</code> 最大分箱数。仅当<code>tree_method</code>设置为<code>hist</code>或<code>approx</code>时使用。default=256<br />
Monotonic Constraints 单调约束<br />
Feature Interaction Constraints 特征交互约束</li>
</ul>
<h2 id="决策树生成"><a class="markdownIt-Anchor" href="#决策树生成"></a> 决策树生成</h2>
<ul>
<li><code>tree_method</code> XGBoost中使用的树构造算法。default=<code>auto</code>
<ul>
<li><code>auto</code>：与<code>hist</code>树方法相同。</li>
<li><code>exact</code>：精确的贪婪算法。列举所有拆分候选。</li>
<li><code>approx</code>：使用分位数草图和梯度直方图的近似贪婪算法。</li>
<li><code>hist</code>：直方图算法。</li>
<li>对于<code>refresh</code>等其他更新程序，请直接设置参数<code>updater</code>。</li>
</ul>
</li>
<li><code>max_depth</code> 一棵树的最大深度。default=6</li>
<li><code>max_leaves</code> 要添加的最大节点数。default=0</li>
<li><code>min_child_weight</code> 每个节点所需的最小实例数量。default=1</li>
<li><code>grow_policy</code> 控制将新节点添加到树中的方式，目前仅在<code>tree_method</code>设置为<code>hist</code>或<code>approx</code>时支持。。default=<code>depthwise</code>
<ul>
<li><code>depthwise</code>：在最靠近根的节点上拆分。</li>
<li><code>lossguide</code>：在损失变化最大的节点上拆分。</li>
</ul>
</li>
</ul>
<h2 id="迭代过程"><a class="markdownIt-Anchor" href="#迭代过程"></a> 迭代过程</h2>
<ul>
<li><code>eta</code>  学习率，范围 [0,1]。default=0.3，别名 <code>learning_rate</code></li>
<li><code>lambda</code> L2正则化系数。default=1，别名 <code>reg_lambda</code></li>
<li><code>alpha</code> L1正则化系数。default=0，别名：<code>reg_alpha</code></li>
<li><code>gamma</code> 依照叶子总量对目标函数施加惩罚的系数。default=0，别名：<code>min_split_loss</code></li>
</ul>
<p>目标函数</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>O</mi><mi>b</mi><msub><mi>j</mi><mi>k</mi></msub><mo>=</mo><munder><mo>∑</mo><mi>i</mi></munder><mi>l</mi><mo stretchy="false">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo separator="true">,</mo><mover accent="true"><msub><mi>y</mi><mi>i</mi></msub><mo>^</mo></mover><mo stretchy="false">)</mo><mo>+</mo><mi>γ</mi><mi>T</mi><mo>+</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mi>λ</mi><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover><msubsup><mi>w</mi><mi>j</mi><mn>2</mn></msubsup><mo>+</mo><mi>α</mi><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover><msub><mi>w</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">Obj_k = \sum_{i}l(y_i,\hat{y_i}) + \gamma T + \frac{1}{2}\lambda\sum_{j=1}^Tw_j^2 + \alpha\sum_{j=1}^Tw_j
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault">b</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05724em;">j</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.05724em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.327674em;vertical-align:-1.277669em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0500050000000003em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05556em;">γ</span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:3.2421130000000007em;vertical-align:-1.4137769999999998em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathdefault">λ</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000006em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4137769999999998em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.864108em;"><span style="top:-2.4530000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:3.2421130000000007em;vertical-align:-1.4137769999999998em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000006em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4137769999999998em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p>其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span></span></span></span>表示当前第<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span>棵树上的叶子总量，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">w_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>则代表当前树上第<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05724em;">j</span></span></span></span>片叶子的叶子权重（leaf weights），即当前叶子<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05724em;">j</span></span></span></span>的预测值。正则项有两个：使用平方的 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="normal">ℓ</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\ell_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord">ℓ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>正则项与使用绝对值的 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="normal">ℓ</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\ell_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord">ℓ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>正则项。</p>
<ul>
<li><code>subsample</code> 训练集的采样比率。子采样将在每次提升迭代中发生一次。default=1</li>
<li><code>sampling_method</code> 训练集的子采样方法。default=<code>uniform</code>
<ul>
<li><code>uniform</code>：每个训练实例被选中的概率相等。通常设置<code>subsample</code>&gt;= 0.5以获得良好的结果。</li>
<li><code>gradient_based</code>：每个训练实例的选择概率与梯度的<em>正则化绝对值</em>成正比。更具体地说，<code>subsample</code>可以设置为低至0.1，而不会损失模型准确性。请注意，仅当<code>tree_method</code>设置为<code>hist</code>且设备为<code>cuda</code>才支持此采样方法；其他树方法仅支持<code>uniform</code>采样。</li>
</ul>
</li>
<li><code>colsample_bytree</code>, <code>colsample_bylevel</code>, <code>colsample_bynode</code> 这是用于特征子采样的参数系列。default=1
<ul>
<li><code>colsample_bytree</code>是构建每棵树时列的子采样比率。每构建一棵树，子采样都会发生一次。</li>
<li><code>colsample_bylevel</code>是每个级别的列的子采样比率。每在树上达到一个新的深度水平，就会进行子采样。是从当前树的列集进行子采样的。</li>
<li><code>colsample_bynode</code>是每个节点（拆分）的列子采样比率。每次评估新的拆分时，子采样都会发生一次。是从当前级别的列集进行子采样的。</li>
<li><code>colsample_by*</code>参数累积工作。例如，具有64个特征的组合<code>&#123;'colsample_bytree':0.5,'colsample_bylevel':0.5,'colsample_bynode':0.5&#125;</code>将在每次拆分时留下8个特征可供选择。</li>
<li>构建数据集时，可以为DMatrix设置<code>feature_weights</code>，以定义使用列采样时选择每个特征的概率。sklearn界面中的<code>fit</code>方法有一个类似的参数。</li>
</ul>
</li>
<li><code>updater</code> 提供了构建和修改树的模块化方式。这是一个高级参数，通常会自动设置。
<ul>
<li><code>grow_colmaker</code>：非分布式柱式树结构。</li>
<li><code>grow_histmaker</code>：基于直方图计数的全局提案，基于行的数据拆分的分布式树结构。</li>
<li><code>grow_quantile_histmaker</code>：使用量化直方图构建树。</li>
<li><code>grow_gpu_hist</code>：当<code>tree_method</code>与<code>device=cuda</code>一起设置为<code>hist</code>启用。</li>
<li><code>grow_gpu_approx</code>：当<code>tree_method</code>与<code>device=cuda</code>一起设置为<code>approx</code>启用。</li>
<li><code>sync</code>：同步所有分布式节点中的树。</li>
<li><code>refresh</code>：根据当前数据刷新树的叶节点权重和/或叶节点值。请注意，不会对数据行进行随机子采样。</li>
<li><code>prune</code>：修剪损失小于 <code>min_split_loss</code>（或<code>gamma</code>）和深度大于<code>max_depth</code>的节点。</li>
</ul>
</li>
<li><code>refresh_leaf</code> 这是<code>refresh</code>更新程序的一个参数。当设置为1时，叶节点值和权重都会更新。当设置为0时，只更新叶节点权重。default=1</li>
<li><code>process_type</code> 指定提升过程。default=<code>default</code>
<ul>
<li><code>default</code>：创造新树的正常提升过程。</li>
<li><code>update</code>：从现有模型开始，仅更新现有的树。在每次提升迭代中，从初始模型中获取一棵树，为该树运行指定的更新程序，并将修改后的树添加到新模型中。新模型将具有相同或更少的树，这取决于执行的增强迭代次数。目前，仅 <code>updater</code> 设置为 <code>refresh</code>或<code>prune</code>时有意义。使用<code>process_type=update</code>时，不能使用创建新树的更新程序。</li>
</ul>
</li>
<li><code>max_delta_step</code> 一次迭代中所允许的最大迭代值。通常不需要这个参数，但当类极度不平衡时，它可能有助于逻辑回归。将其设置为1-10的值可能有助于控制更新。default=0</li>
</ul>
<p><strong>树方法</strong>：对于训练 boosted tree 模型，有2个参数用于选择算法，即updater和tree_method。XGBoost有3种内置树方法，即exact、approx和hist。除了这些树方法外，还有一些独立的更新程序，包括refresh、prune和sync。参数updater比tree_method更原始，因为后者只是前者的预配置，差异主要是由于历史原因。</p>
<h2 id="模型训练"><a class="markdownIt-Anchor" href="#模型训练"></a> 模型训练</h2>
<ul>
<li><code>objective</code> 选择需要优化的损失函数。default=<code>reg:squarederror</code>
<ul>
<li>回归问题： <code>reg:squarederror</code>、 <code>reg:squaredlogerror</code>、 <code>reg:pseudohubererror</code>、<code>reg:absoluteerror</code>、<code>reg:quantileerror</code>、<code>pinballloss</code>、<code>count:poisson</code>、<code>reg:gamma</code>、<code>reg:tweedie</code></li>
<li>分类问题： <code>reg:logistic</code>、 <code>binary:logistic</code>、 <code>binary:logitraw</code>、<code>binary:hinge</code>、<code>multi:softprob</code>、<code>multi:softmax</code></li>
<li>生存分析：<code>survival:cox</code>、 <code>survival:aft</code></li>
<li>排序问题：<code>rank:ndcg</code>、 <code>rank:map</code>、<code>rank:pairwise</code></li>
</ul>
</li>
<li><code>base_score</code> 初始化预测结果<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>H</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">H_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.08125em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的设置</li>
<li><code>eval_metric</code> 评估指标。将根据 <code>objective</code>分配默认值：回归的rmse，分类的logloss，<code>rank:map</code>的平均精度等。支持添加多个评估指标。
<ul>
<li>回归问题： <code>rmse</code>、<code>rmsle</code>、<code>mae</code>、 <code>mape</code>、<code>mphe</code></li>
<li>分类问题：<code>logloss</code>、 <code>error</code>、<code>error@t</code> 可以通过 t 来指定与0.5不同的二分类阈值、 <code>merror</code>、 <code>mlogloss</code>、 <code>auc</code>、<code>aucpr</code>、 <code>map</code></li>
</ul>
</li>
<li><code>disable_default_eval_metric</code>：是否禁用默认评估函数。default= False</li>
</ul>
<table>
<thead>
<tr>
<th>module</th>
<th>comment</th>
</tr>
</thead>
<tbody>
<tr>
<td>xgboost.train</td>
<td>指定参数训练</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener external nofollow noreferrer" href="http://xgboost.cv">xgboost.cv</a></td>
<td>交叉验证训练</td>
</tr>
</tbody>
</table>
<p>主要参数：</p>
<ul>
<li>params - Booster 参数字典</li>
<li>dtrain 用于训练的数据集</li>
<li>num_boost_round 提升迭代次数，即生成的基学习器的数量</li>
<li>evals 验证/测试数据</li>
<li>obj 自定义目标函数</li>
<li>feval 自定义评估函数（已废弃）</li>
<li>maximize 是否最大化 feval</li>
<li>early_stopping_rounds 提前停止，需要至少一个evals。如果evals、eval_metric不止一个，则选用最后一个判断提前停止</li>
<li>evals_result 记录验证集的评估结果</li>
<li>verbose_eval</li>
<li>xgb_model 初始化模型，允许继续训练</li>
<li>callbacks 回调函数列表</li>
<li>custom_metric 自定义评估函数</li>
<li>nfold CV值</li>
<li>stratified 是否分层抽样</li>
<li>folds sklearn  - a KFold or StratifiedKFold instance or list of fold indices</li>
<li>as_pandas 是否转化为pandas</li>
<li>show_stdv 是否打印标准差</li>
</ul>
<h2 id="回调参数"><a class="markdownIt-Anchor" href="#回调参数"></a> 回调参数</h2>
<table>
<thead>
<tr>
<th>方法</th>
<th>Create a callback</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>xgboost.callback.TrainingCallback</code></td>
<td>Interface for training callback.</td>
</tr>
<tr>
<td><code>xgboost.callback.EvaluationMonitor(rank=0, period=1, show_stdv=False)</code></td>
<td>输出评估结果的频率</td>
</tr>
<tr>
<td><code>xgboost.callback.EarlyStopping(rounds)</code></td>
<td>回调提前停止策略，控制过拟合风险，当验证集上的精度若干轮不下降，提前停止训练。</td>
</tr>
<tr>
<td><code>xgboost.callback.LearningRateScheduler(learning_rates)</code></td>
<td>调度学习率</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">D_train = xgb.DMatrix(X_train, y_train)</span><br><span class="line">D_valid = xgb.DMatrix(X_valid, y_valid)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define a custom evaluation metric used for early stopping.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">eval_error_metric</span>(<span class="params">predt, dtrain: xgb.DMatrix</span>):</span></span><br><span class="line">    label = dtrain.get_label()</span><br><span class="line">    r = np.zeros(predt.shape)</span><br><span class="line">    gt = predt &gt; <span class="number">0.5</span></span><br><span class="line">    r[gt] = <span class="number">1</span> - label[gt]</span><br><span class="line">    le = predt &lt;= <span class="number">0.5</span></span><br><span class="line">    r[le] = label[le]</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;CustomErr&#x27;</span>, np.<span class="built_in">sum</span>(r)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Specify which dataset and which metric should be used for early stopping.</span></span><br><span class="line">early_stop = xgb.callback.EarlyStopping(rounds=early_stopping_rounds,</span><br><span class="line">                                        metric_name=<span class="string">&#x27;CustomErr&#x27;</span>,</span><br><span class="line">                                        data_name=<span class="string">&#x27;Train&#x27;</span>)</span><br><span class="line"></span><br><span class="line">booster = xgb.train(</span><br><span class="line">    params = &#123;<span class="string">&#x27;objective&#x27;</span>: <span class="string">&#x27;binary:logistic&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;eval_metric&#x27;</span>: [<span class="string">&#x27;error&#x27;</span>, <span class="string">&#x27;rmse&#x27;</span>],</span><br><span class="line">              <span class="string">&#x27;tree_method&#x27;</span>: <span class="string">&#x27;hist&#x27;</span>&#125;, </span><br><span class="line">    dtrain = D_train,</span><br><span class="line">    evals=[(D_train, <span class="string">&#x27;Train&#x27;</span>), (D_valid, <span class="string">&#x27;Valid&#x27;</span>)],</span><br><span class="line">    feval=eval_error_metric,</span><br><span class="line">    num_boost_round=<span class="number">1000</span>,</span><br><span class="line">    callbacks=[early_stop],</span><br><span class="line">    verbose_eval=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<h2 id="自定义损失函数"><a class="markdownIt-Anchor" href="#自定义损失函数"></a> 自定义损失函数</h2>
<p>xgboost 在 xgb.train中通过参数obj和custom_metric来自定损失函数和评估函数。</p>
<p>自定义损失函数接受predt和dtrain作为输入，返回损失函数的一阶(grad)和二阶(hess)导数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Tuple</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient</span>(<span class="params">predt: np.ndarray, dtrain: xgb.DMatrix</span>) -&gt; np.ndarray:</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;Compute the gradient squared log error.&#x27;&#x27;&#x27;</span></span><br><span class="line">    y = dtrain.get_label()</span><br><span class="line">    <span class="keyword">return</span> (np.log1p(predt) - np.log1p(y)) / (predt + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hessian</span>(<span class="params">predt: np.ndarray, dtrain: xgb.DMatrix</span>) -&gt; np.ndarray:</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;Compute the hessian for squared log error.&#x27;&#x27;&#x27;</span></span><br><span class="line">    y = dtrain.get_label()</span><br><span class="line">    <span class="keyword">return</span> ((-np.log1p(predt) + np.log1p(y) + <span class="number">1</span>) /</span><br><span class="line">            np.power(predt + <span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">squared_log</span>(<span class="params">predt: np.ndarray,</span></span></span><br><span class="line"><span class="params"><span class="function">                dtrain: xgb.DMatrix</span>) -&gt; <span class="type">Tuple</span>[np.ndarray, np.ndarray]:</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;Squared Log Error objective. A simplified version for RMSLE used as</span></span><br><span class="line"><span class="string">    objective function.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    :math:`\frac&#123;1&#125;&#123;2&#125;[log(pred + 1) - log(label + 1)]^2`</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    predt[predt &lt; -<span class="number">1</span>] = -<span class="number">1</span> + <span class="number">1e-6</span></span><br><span class="line">    grad = gradient(predt, dtrain)</span><br><span class="line">    hess = hessian(predt, dtrain)</span><br><span class="line">    <span class="keyword">return</span> grad, hess</span><br></pre></td></tr></table></figure>
<p>自定义损失函数后，模型的输出不在是 [0,1] 概率输出，而是 sigmoid 函数之前的输入值。因此，需要写出对应的评估函数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rmsle</span>(<span class="params">predt: np.ndarray, dtrain: xgb.DMatrix</span>) -&gt; <span class="type">Tuple</span>[<span class="built_in">str</span>, <span class="built_in">float</span>]:</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; Root mean squared log error metric.&#x27;&#x27;&#x27;</span></span><br><span class="line">    y = dtrain.get_label()</span><br><span class="line">    predt[predt &lt; -<span class="number">1</span>] = -<span class="number">1</span> + <span class="number">1e-6</span></span><br><span class="line">    elements = np.power(np.log1p(y) - np.log1p(predt), <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;PyRMSLE&#x27;</span>, <span class="built_in">float</span>(np.sqrt(np.<span class="built_in">sum</span>(elements) / <span class="built_in">len</span>(y)))</span><br></pre></td></tr></table></figure>
<p>评估函数也接受predt和dtrain作为输入，返回本身的名称和浮点值作为结果。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">xgb.train(&#123;<span class="string">&#x27;tree_method&#x27;</span>: <span class="string">&#x27;hist&#x27;</span>, <span class="string">&#x27;seed&#x27;</span>: <span class="number">1994</span>,</span><br><span class="line">           <span class="string">&#x27;disable_default_eval_metric&#x27;</span>: <span class="number">1</span>&#125;,</span><br><span class="line">          dtrain=dtrain,</span><br><span class="line">          num_boost_round=<span class="number">10</span>,</span><br><span class="line">          obj=squared_log,</span><br><span class="line">          custom_metric=rmsle,</span><br><span class="line">          evals=[(dtrain, <span class="string">&#x27;dtrain&#x27;</span>), (dtest, <span class="string">&#x27;dtest&#x27;</span>)],</span><br><span class="line">          evals_result=results)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>请注意，参数disable_default_eval_metric用于抑制XGBoost中的默认度量。</p>
</blockquote>
<p>当自定义损失函数后，模型 <code>predict</code> 将会输出原始值，需要手动进行sigmoid函数变换。可以通过<code>predict</code>函数中的<code>output_margin</code>参数来控制</p>
<h1 id="scikit-learn-api"><a class="markdownIt-Anchor" href="#scikit-learn-api"></a> Scikit-Learn API</h1>
<p>XGBoost的原生代码与我们已经习惯了的sklearn代码有很大的不同。对于熟悉sklearn的我们来说，许多人也会倾向于使用xgboost自带的sklearn接口来实现算法。通过这个接口，我们可以使用跟sklearn代码一样的方式来实现xgboost，即可以通过fit和predict等接口来执行训练预测过程，也可以调用属性比如coef_等。</p>
<p>在XGBoost的sklearn API中，我们可以看到下面五个类：</p>
<table>
<thead>
<tr>
<th>module</th>
<th>comment</th>
</tr>
</thead>
<tbody>
<tr>
<td>XGBRegressor</td>
<td>实现xgboost回归</td>
</tr>
<tr>
<td>XGBClassifier</td>
<td>实现xgboost分类</td>
</tr>
<tr>
<td>XGBRanker</td>
<td>实现xgboost排序</td>
</tr>
<tr>
<td>XGBRFClassifier</td>
<td>基于xgboost库实现随机森林分类</td>
</tr>
<tr>
<td>XGBRFRegressor</td>
<td>基于xgboost库实现随机森林回归</td>
</tr>
</tbody>
</table>
<p>其中XGBRF的两个类是以XGBoost方式建树、但以bagging方式构建森林的类，通常只有在我们使用普通随机森林效果不佳、但又不希望使用Boosting的时候使用。这种使用XGBoost方式建树的森林在sklearn中已经开始了实验，不过还没有正式上线。</p>
<p>另外两个类就很容易理解了，一个是XGBoost的回归，一个是XGBoost的分类。这两个类的参数高度相似，我们可以以XGBoost分类为例查看：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">XGBClassifier(</span><br><span class="line">    n_estimators : <span class="built_in">int</span> = <span class="literal">None</span>,</span><br><span class="line">    max_depth : <span class="built_in">int</span> = <span class="literal">None</span>,</span><br><span class="line">    max_leaves : <span class="built_in">int</span> = <span class="literal">None</span>,</span><br><span class="line">    max_bin : <span class="built_in">int</span> = <span class="literal">None</span>,</span><br><span class="line">    grow_policy : &#123;<span class="number">0</span>, <span class="number">1</span>&#125; = <span class="literal">None</span>,</span><br><span class="line">    learning_rate : <span class="built_in">float</span> = <span class="literal">None</span>,</span><br><span class="line">    objective: <span class="type">Union</span>[<span class="built_in">str</span>, <span class="type">Callable</span>, NoneType] = <span class="string">&quot;binary:logistic&quot;</span>,</span><br><span class="line">    booster : <span class="built_in">str</span> = <span class="literal">None</span>, <span class="comment"># gbtree, gblinear or dart.</span></span><br><span class="line">    tree_method : <span class="built_in">str</span> = <span class="literal">None</span>,</span><br><span class="line">    n_jobs : <span class="built_in">int</span> = <span class="literal">None</span>,</span><br><span class="line">    gamma : <span class="built_in">float</span> = <span class="literal">None</span>,</span><br><span class="line">    min_child_weight : <span class="built_in">float</span> = <span class="literal">None</span>,</span><br><span class="line">    max_delta_step : <span class="built_in">float</span> = <span class="literal">None</span>,</span><br><span class="line">    subsample : <span class="built_in">float</span> = <span class="literal">None</span>,</span><br><span class="line">    sampling_method : &#123;<span class="string">&quot;uniform&quot;</span>, <span class="string">&quot;gradient_based&quot;</span>&#125; = <span class="literal">None</span>,</span><br><span class="line">    colsample_bytree : <span class="built_in">float</span> = <span class="literal">None</span>,</span><br><span class="line">    colsample_bylevel : <span class="built_in">float</span> = <span class="literal">None</span>,</span><br><span class="line">    colsample_bynode : <span class="built_in">float</span> = <span class="literal">None</span>,</span><br><span class="line">    reg_alpha : <span class="built_in">float</span> = <span class="literal">None</span>,</span><br><span class="line">    reg_lambda : <span class="built_in">float</span> = <span class="literal">None</span>,</span><br><span class="line">    scale_pos_weight : <span class="built_in">float</span> = <span class="literal">None</span>,</span><br><span class="line">    base_score : NoneType = <span class="literal">None</span>,</span><br><span class="line">    missing : <span class="built_in">float</span> = np.nan,</span><br><span class="line">    num_parallel_tree : <span class="built_in">int</span> = <span class="literal">None</span>,</span><br><span class="line">    monotone_constraints : <span class="type">Union</span>[<span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">int</span>], <span class="built_in">str</span>]] = <span class="literal">None</span>,</span><br><span class="line">    interaction_constraints : <span class="type">Union</span>[<span class="built_in">str</span>, <span class="type">List</span>[<span class="type">Tuple</span>[<span class="built_in">str</span>]]] = <span class="literal">None</span>, </span><br><span class="line">    importance_type : <span class="built_in">str</span> = <span class="literal">None</span>,</span><br><span class="line">    device : &#123;<span class="string">&quot;cpu&quot;</span>, <span class="string">&quot;cuda&quot;</span>, <span class="string">&quot;gpu&quot;</span>&#125; = <span class="literal">None</span>,</span><br><span class="line">    validate_parameters : <span class="built_in">bool</span> = <span class="literal">None</span>,</span><br><span class="line">    enable_categorical : <span class="built_in">bool</span> = <span class="literal">False</span>,</span><br><span class="line">    feature_types : FeatureTypes = <span class="literal">None</span>,</span><br><span class="line">    max_cat_to_onehot : <span class="built_in">int</span> = <span class="literal">None</span>,</span><br><span class="line">    max_cat_threshold : <span class="built_in">int</span> = <span class="literal">None</span>,</span><br><span class="line">    multi_strategy : &#123;<span class="string">&quot;one_output_per_tree&quot;</span>, <span class="string">&quot;multi_output_tree&quot;</span>&#125; = <span class="literal">None</span>,</span><br><span class="line">    eval_metric : <span class="type">Union</span>[<span class="built_in">str</span>, <span class="type">List</span>[<span class="built_in">str</span>], <span class="type">Callable</span>] = <span class="literal">None</span>,</span><br><span class="line">    early_stopping_rounds : <span class="built_in">int</span> = <span class="literal">None</span>,</span><br><span class="line">    callbacks : <span class="type">List</span>[TrainingCallback] = <span class="literal">None</span>,</span><br><span class="line">    random_state : <span class="type">Union</span>[numpy.random.RandomState, <span class="built_in">int</span>] = <span class="literal">None</span>,</span><br><span class="line">    verbosity : <span class="built_in">int</span> = <span class="literal">None</span>,</span><br><span class="line">    **kwargs : <span class="built_in">dict</span> = <span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>具体的模型训练过程和sklearn中其他模型一样，通过fit进行训练，并利用predict进行结果输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment"># read data</span></span><br><span class="line">X, y = load_iris(return_X_y=<span class="literal">True</span>)</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">.2</span>)</span><br><span class="line"><span class="comment"># create model instance</span></span><br><span class="line">clf = XGBClassifier(n_estimators=<span class="number">2</span>, max_depth=<span class="number">2</span>, learning_rate=<span class="number">1</span>, objective=<span class="string">&#x27;binary:logistic&#x27;</span>)</span><br><span class="line"><span class="comment"># fit model</span></span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line"><span class="comment"># make predictions</span></span><br><span class="line">preds = clf.predict(X_test)</span><br><span class="line"><span class="comment"># Save model into JSON format.</span></span><br><span class="line">clf.save_model(<span class="string">&quot;clf.json&quot;</span>)</span><br></pre></td></tr></table></figure>
<h1 id="可视化"><a class="markdownIt-Anchor" href="#可视化"></a> 可视化</h1>
<table>
<thead>
<tr>
<th style="text-align:left">module</th>
<th style="text-align:left">comment</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">plot_importance(booster)</td>
<td style="text-align:left">绘制模型的特征重要性。</td>
</tr>
<tr>
<td style="text-align:left">plot_tree(booster)</td>
<td style="text-align:left">绘制指定的树</td>
</tr>
<tr>
<td style="text-align:left">to_graphviz(booster)</td>
<td style="text-align:left">创建指定树的二叉图文件</td>
</tr>
</tbody>
</table>
<h1 id="继续训练"><a class="markdownIt-Anchor" href="#继续训练"></a> 继续训练</h1>
<p>XGBoost提供两种增量学习的方式：</p>
<ul>
<li>一种是在当前迭代树的基础上增加新树，原树不变；</li>
<li>一种是当前迭代树结构不变，重新计算叶节点权重和/或叶节点值。</li>
</ul>
<p><a href="/ipynb/incremental_learning_demo.html#XGBoost">Jupyter notebook 增量学习Demo</a></p>
<p>在初始化模型 <code>xgb_model</code> 上继续训练</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Train 128 iterations, with the first one runs for 32 iterations and</span></span><br><span class="line"><span class="comment"># the second one runs for 96 iterations</span></span><br><span class="line">clf1 = xgboost.XGBClassifier(n_estimators=<span class="number">32</span>)</span><br><span class="line">clf1.fit(X, y, eval_set=[(X, y)], eval_metric=<span class="string">&quot;logloss&quot;</span>)</span><br><span class="line"><span class="keyword">assert</span> clf1.get_booster().num_boosted_rounds() == <span class="number">32</span></span><br><span class="line"></span><br><span class="line">clf2 = xgboost.XGBClassifier(n_estimators=<span class="number">128</span> - <span class="number">32</span>)</span><br><span class="line">clf2.fit(X, y, eval_set=[(X, y)], eval_metric=<span class="string">&quot;logloss&quot;</span>, xgb_model=clf1)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Total boosted rounds:&quot;</span>, clf.get_booster().num_boosted_rounds())</span><br></pre></td></tr></table></figure>
<p>使用<code>process_type</code>参数更新叶节点</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># using `process_type` with `prune` and `refresh`</span></span><br><span class="line">n_rounds=<span class="number">32</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Train a model first</span></span><br><span class="line">Xy = xgb.DMatrix(X_train, y_train)</span><br><span class="line">evals_result = &#123;&#125;</span><br><span class="line">booster = xgb.train(</span><br><span class="line">    &#123;<span class="string">&quot;tree_method&quot;</span>: <span class="string">&quot;hist&quot;</span>, <span class="string">&quot;max_depth&quot;</span>: <span class="number">6</span>, <span class="string">&quot;device&quot;</span>: <span class="string">&quot;cuda&quot;</span>&#125;,</span><br><span class="line">    Xy,</span><br><span class="line">    num_boost_round=n_rounds,</span><br><span class="line">    evals=[(Xy, <span class="string">&quot;Train&quot;</span>)],</span><br><span class="line">    evals_result=evals_result,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Refresh the leaf value and tree statistic</span></span><br><span class="line">Xy_refresh = xgb.DMatrix(X_refresh, y_refresh)</span><br><span class="line"><span class="comment"># The model will adapt to new data by changing leaf value (no change in</span></span><br><span class="line"><span class="comment"># split condition) with refresh_leaf set to True.</span></span><br><span class="line">refresh_result = &#123;&#125;</span><br><span class="line">refreshed = xgb.train(</span><br><span class="line">    &#123;<span class="string">&quot;process_type&quot;</span>: <span class="string">&quot;update&quot;</span>, <span class="string">&quot;updater&quot;</span>: <span class="string">&quot;refresh&quot;</span>, <span class="string">&quot;refresh_leaf&quot;</span>: <span class="literal">True</span>&#125;,</span><br><span class="line">    Xy_refresh,</span><br><span class="line">    num_boost_round=n_rounds,</span><br><span class="line">    xgb_model=booster,</span><br><span class="line">    evals=[(Xy, <span class="string">&quot;Original&quot;</span>), (Xy_refresh, <span class="string">&quot;Train&quot;</span>)],</span><br><span class="line">    evals_result=refresh_result,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Refresh the model without changing the leaf value, but tree statistic including</span></span><br><span class="line"><span class="comment"># cover and weight are refreshed.</span></span><br><span class="line">refresh_result = &#123;&#125;</span><br><span class="line">refreshed = xgb.train(</span><br><span class="line">    &#123;<span class="string">&quot;process_type&quot;</span>: <span class="string">&quot;update&quot;</span>, <span class="string">&quot;updater&quot;</span>: <span class="string">&quot;refresh&quot;</span>, <span class="string">&quot;refresh_leaf&quot;</span>: <span class="literal">False</span>&#125;,</span><br><span class="line">    Xy_refresh,</span><br><span class="line">    num_boost_round=n_rounds,</span><br><span class="line">    xgb_model=booster,</span><br><span class="line">    evals=[(Xy, <span class="string">&quot;Original&quot;</span>), (Xy_refresh, <span class="string">&quot;Train&quot;</span>)],</span><br><span class="line">    evals_result=refresh_result,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prune the trees with smaller max_depth</span></span><br><span class="line">Xy_update = xgb.DMatrix(X_update, y_update)</span><br><span class="line">prune_result = &#123;&#125;</span><br><span class="line">pruned = xgb.train(</span><br><span class="line">    &#123;<span class="string">&quot;process_type&quot;</span>: <span class="string">&quot;update&quot;</span>, <span class="string">&quot;updater&quot;</span>: <span class="string">&quot;prune&quot;</span>, <span class="string">&quot;max_depth&quot;</span>: <span class="number">2</span>&#125;,</span><br><span class="line">    Xy_update,</span><br><span class="line">    num_boost_round=n_rounds,</span><br><span class="line">    xgb_model=booster,</span><br><span class="line">    evals=[(Xy, <span class="string">&quot;Original&quot;</span>), (Xy_update, <span class="string">&quot;Train&quot;</span>)],</span><br><span class="line">    evals_result=prune_result,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h1 id="分布式学习"><a class="markdownIt-Anchor" href="#分布式学习"></a> 分布式学习</h1>
<h2 id="xgboost-with-pyspark"><a class="markdownIt-Anchor" href="#xgboost-with-pyspark"></a> XGBoost with PySpark</h2>
<blockquote>
<p>从1.7.0版本开始，xgboost已经封装了pyspark API，因此不需要纠结spark版本对应的jar包 xgboost4j 和 xgboost4j-spark 的下载问题了，也不需要下载调度包 sparkxgb.zip。</p>
</blockquote>
<table>
<thead>
<tr>
<th>算法</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener external nofollow noreferrer" href="https://xgboost.readthedocs.io/en/stable/python/python_api.html#module-xgboost.spark">xgboost.spark.SparkXGBClassifier</a></td>
<td>PySpark分类算法</td>
</tr>
<tr>
<td>xgboost.spark.SparkXGBRegressor</td>
<td>PySpark回归算法</td>
</tr>
<tr>
<td>xgboost.spark.SparkXGBRanker</td>
<td>PySpark排名算法</td>
</tr>
</tbody>
</table>
<p><a href="/ipynb/distributed_learning_demo.html#XGBoost-with-spark">Jupyter notebook 分布式学习Demo</a></p>
<p>以 SparkXGBClassifier 为例，介绍下XGBoost在spark中的用法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">xgboost.spark.SparkXGBClassifier(</span><br><span class="line">    features_col=<span class="string">&#x27;features&#x27;</span>, </span><br><span class="line">    label_col=<span class="string">&#x27;label&#x27;</span>, </span><br><span class="line">    prediction_col=<span class="string">&#x27;prediction&#x27;</span>, </span><br><span class="line">    probability_col=<span class="string">&#x27;probability&#x27;</span>, </span><br><span class="line">    raw_prediction_col=<span class="string">&#x27;rawPrediction&#x27;</span>, </span><br><span class="line">    pred_contrib_col=<span class="literal">None</span>, </span><br><span class="line">    validation_indicator_col=<span class="literal">None</span>, </span><br><span class="line">    weight_col=<span class="literal">None</span>, </span><br><span class="line">    base_margin_col=<span class="literal">None</span>, </span><br><span class="line">    num_workers=<span class="number">1</span>, </span><br><span class="line">    use_gpu=<span class="literal">None</span>, </span><br><span class="line">    device=<span class="literal">None</span>, </span><br><span class="line">    force_repartition=<span class="literal">False</span>, </span><br><span class="line">    repartition_random_shuffle=<span class="literal">False</span>, </span><br><span class="line">    enable_sparse_data_optim=<span class="literal">False</span>, </span><br><span class="line">    **kwargs)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> xgboost.spark <span class="keyword">import</span> SparkXGBClassifier</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.master(<span class="string">&quot;local[*]&quot;</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line"><span class="comment"># create dataset</span></span><br><span class="line">df_train = spark.createDataFrame([</span><br><span class="line">    (Vectors.dense(<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>), <span class="number">0</span>, <span class="literal">False</span>, <span class="number">1.0</span>),</span><br><span class="line">    (Vectors.sparse(<span class="number">3</span>, &#123;<span class="number">1</span>: <span class="number">1.0</span>, <span class="number">2</span>: <span class="number">5.5</span>&#125;), <span class="number">1</span>, <span class="literal">False</span>, <span class="number">2.0</span>),</span><br><span class="line">    (Vectors.dense(<span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">6.0</span>), <span class="number">0</span>, <span class="literal">True</span>, <span class="number">1.0</span>),</span><br><span class="line">    (Vectors.sparse(<span class="number">3</span>, &#123;<span class="number">1</span>: <span class="number">6.0</span>, <span class="number">2</span>: <span class="number">7.5</span>&#125;), <span class="number">1</span>, <span class="literal">True</span>, <span class="number">2.0</span>),</span><br><span class="line">], [<span class="string">&quot;features&quot;</span>, <span class="string">&quot;label&quot;</span>, <span class="string">&quot;isVal&quot;</span>, <span class="string">&quot;weight&quot;</span>])</span><br><span class="line">df_test = spark.createDataFrame([</span><br><span class="line">    (Vectors.dense(<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>), ),</span><br><span class="line">], [<span class="string">&quot;features&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># train xgboost classifier model</span></span><br><span class="line">clf = SparkXGBClassifier(max_depth=<span class="number">5</span>, missing=<span class="number">0.0</span>,</span><br><span class="line">    validation_indicator_col=<span class="string">&#x27;isVal&#x27;</span>, weight_col=<span class="string">&#x27;weight&#x27;</span>,</span><br><span class="line">    early_stopping_rounds=<span class="number">1</span>, eval_metric=<span class="string">&#x27;logloss&#x27;</span>)</span><br><span class="line">model = xgb_classifier.fit(df_train)</span><br><span class="line">predict_df = model.transform(df_test)</span><br><span class="line"></span><br><span class="line">classifier_evaluator = MulticlassClassificationEvaluator(metricName=<span class="string">&quot;f1&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;classifier f1=<span class="subst">&#123;classifier_evaluator.evaluate(predict_df)&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><a class="post-meta__tags" href="/tags/python/">python</a></div><div class="post_share"><div class="social-share" data-image="/img/XGBoost-cover.svg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/morty3.jpg" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/morty3.jpg" alt="Give me money!"/></a><div class="post-qr-code-desc">Give me money!</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/ce19bbb1/" title="特征工程(II)--数据预处理"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/FeatureEngine.png" onerror="onerror=null;src='/img/404_moon.png'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">特征工程(II)--数据预处理</div></div></a></div><div class="next-post pull-right"><a href="/posts/ca507391/" title="特征工程(III)--特征构造"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/FeatureEngine.png" onerror="onerror=null;src='/img/404_moon.png'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">特征工程(III)--特征构造</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/90489eb7/" title="PySpark机器学习Demo"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/spark-install.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-05-17</div><div class="title">PySpark机器学习Demo</div></div></a></div><div><a href="/posts/75974533/" title="大数据手册(Spark)--PySpark MLlib"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/apache-spark-mllib.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-05-01</div><div class="title">大数据手册(Spark)--PySpark MLlib</div></div></a></div><div><a href="/posts/3d0ef432/" title="特征工程(VI)--机器学习"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/FeatureEngine.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-04-20</div><div class="title">特征工程(VI)--机器学习</div></div></a></div><div><a href="/posts/794d8498/" title="Python(Machine Learning)--超参数优化"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/Hyperparameter-Optimization.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-15</div><div class="title">Python(Machine Learning)--超参数优化</div></div></a></div><div><a href="/posts/425f9947/" title="特征工程(VII)--模型集成"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/FeatureEngine.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-04-20</div><div class="title">特征工程(VII)--模型集成</div></div></a></div><div><a href="/posts/861261b5/" title="Python(Machine Learning)--sklearn"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/sklearn-cover.svg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2018-05-10</div><div class="title">Python(Machine Learning)--sklearn</div></div></a></div></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div><div id="comment-switch"><span class="first-comment">Gitalk</span><span class="switch-btn"></span><span class="second-comment">Waline</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div><div><div id="waline-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Tiny Lei</div><div class="author-info__description">每天进步一点点...</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">175</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">108</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">43</div></a></div><div class="card-info-social-icons is-center"><a class="social-icon" href="https://gitee.com/wilenwu" rel="external nofollow noreferrer" target="_blank" title="Gitee"><i class="iconfont icon-gitee"></i></a><a class="social-icon" href="https://github.com/wilenwu" rel="external nofollow noreferrer" target="_blank" title="Github"><i class="iconfont icon-github"></i></a><a class="social-icon" href="https://blog.csdn.net/qq_41518277" rel="external nofollow noreferrer" target="_blank" title="CSDN"><i class="iconfont icon-csdn"></i></a><a class="social-icon" href="/atom.xml" target="_blank" title="RSS"><i class="iconfont icon-rss"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">感谢访问本站，若喜欢请收藏^_^</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#quick-start"><span class="toc-number">1.</span> <span class="toc-text"> Quick Start</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#step-1-load-the-dataset"><span class="toc-number">1.1.</span> <span class="toc-text"> Step 1:  Load the dataset</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#step-2-setting-parameters"><span class="toc-number">1.2.</span> <span class="toc-text"> Step 2: Setting Parameters</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#step-3-training"><span class="toc-number">1.3.</span> <span class="toc-text"> Step 3: Training</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#step-4-save-and-load-model"><span class="toc-number">1.4.</span> <span class="toc-text"> Step 4: Save and load model</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#step-5-predict"><span class="toc-number">1.5.</span> <span class="toc-text"> Step 5:  Predict</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#step-6-evaluating"><span class="toc-number">1.6.</span> <span class="toc-text"> Step 6:  Evaluating</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%82%E6%95%B0"><span class="toc-number">2.</span> <span class="toc-text"> 参数</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E8%88%AC%E5%8F%82%E6%95%B0"><span class="toc-number">2.1.</span> <span class="toc-text"> 一般参数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A0%B7%E6%9C%AC%E5%A4%84%E7%90%86%E5%8F%82%E6%95%B0"><span class="toc-number">2.2.</span> <span class="toc-text"> 样本处理参数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E5%A4%84%E7%90%86%E5%8F%82%E6%95%B0"><span class="toc-number">2.3.</span> <span class="toc-text"> 特征处理参数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E7%94%9F%E6%88%90"><span class="toc-number">2.4.</span> <span class="toc-text"> 决策树生成</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%AD%E4%BB%A3%E8%BF%87%E7%A8%8B"><span class="toc-number">2.5.</span> <span class="toc-text"> 迭代过程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="toc-number">2.6.</span> <span class="toc-text"> 模型训练</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9E%E8%B0%83%E5%8F%82%E6%95%B0"><span class="toc-number">2.7.</span> <span class="toc-text"> 回调参数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">2.8.</span> <span class="toc-text"> 自定义损失函数</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#scikit-learn-api"><span class="toc-number">3.</span> <span class="toc-text"> Scikit-Learn API</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="toc-number">4.</span> <span class="toc-text"> 可视化</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BB%A7%E7%BB%AD%E8%AE%AD%E7%BB%83"><span class="toc-number">5.</span> <span class="toc-text"> 继续训练</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%A6%E4%B9%A0"><span class="toc-number">6.</span> <span class="toc-text"> 分布式学习</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#xgboost-with-pyspark"><span class="toc-number">6.1.</span> <span class="toc-text"> XGBoost with PySpark</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/db6e5578/" title="Java速成指南"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/java_cover.png" onerror="this.onerror=null;this.src='/img/404_moon.png'" alt="Java速成指南"/></a><div class="content"><a class="title" href="/posts/db6e5578/" title="Java速成指南">Java速成指南</a><time datetime="2024-09-17T14:55:05.000Z" title="发表于 2024-09-17 22:55:05">2024-09-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/a14a3278/" title="机器学习(VII)--强化学习(七)Actor-Critic"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/reinforcement_learning_cover.png" onerror="this.onerror=null;this.src='/img/404_moon.png'" alt="机器学习(VII)--强化学习(七)Actor-Critic"/></a><div class="content"><a class="title" href="/posts/a14a3278/" title="机器学习(VII)--强化学习(七)Actor-Critic">机器学习(VII)--强化学习(七)Actor-Critic</a><time datetime="2024-08-29T09:24:00.000Z" title="发表于 2024-08-29 17:24:00">2024-08-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/3644c10c/" title="机器学习(VII)--强化学习(六)策略梯度方法"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/reinforcement_learning_cover.png" onerror="this.onerror=null;this.src='/img/404_moon.png'" alt="机器学习(VII)--强化学习(六)策略梯度方法"/></a><div class="content"><a class="title" href="/posts/3644c10c/" title="机器学习(VII)--强化学习(六)策略梯度方法">机器学习(VII)--强化学习(六)策略梯度方法</a><time datetime="2024-08-29T09:23:00.000Z" title="发表于 2024-08-29 17:23:00">2024-08-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/2bd55622/" title="机器学习(VII)--强化学习(五)值函数近似"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/reinforcement_learning_cover.png" onerror="this.onerror=null;this.src='/img/404_moon.png'" alt="机器学习(VII)--强化学习(五)值函数近似"/></a><div class="content"><a class="title" href="/posts/2bd55622/" title="机器学习(VII)--强化学习(五)值函数近似">机器学习(VII)--强化学习(五)值函数近似</a><time datetime="2024-08-29T09:22:00.000Z" title="发表于 2024-08-29 17:22:00">2024-08-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/363ac257/" title="机器学习(VII)--强化学习(四)时序差分方法"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/reinforcement_learning_cover.png" onerror="this.onerror=null;this.src='/img/404_moon.png'" alt="机器学习(VII)--强化学习(四)时序差分方法"/></a><div class="content"><a class="title" href="/posts/363ac257/" title="机器学习(VII)--强化学习(四)时序差分方法">机器学习(VII)--强化学习(四)时序差分方法</a><time datetime="2024-08-29T09:21:00.000Z" title="发表于 2024-08-29 17:21:00">2024-08-29</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2024 By Tiny Lei</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"><script>(() => {
  const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaid.length === 0) return
  const runMermaid = () => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'forest'

    Array.from($mermaid).forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
      const mermaidID = 'mermaid-' + index
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)

      const renderV10 = () => {
        renderFn.then(({svg}) => {
          mermaidSrc.insertAdjacentHTML('afterend', svg)
        })
      }

      const renderV9 = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      typeof renderFn === 'string' ? renderV9(renderFn) : renderV10()
    })
  }

  const loadMermaid = () => {
    window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
  }

  btf.addModeChange('mermaid', runMermaid)

  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script><script>function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk(Object.assign({
      clientID: '7c65134b48b13f306114',
      clientSecret: 'f049f68368a11925fdb69e57c64839eac94e13c1'',
      repo: 'gitalk-comments',
      owner: 'WilenWu',
      admin: ['WilenWu'],
      id: 'd436437bf23fe54a8192d3b2a5ba2ea5',
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    getCSS('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css')
    getScript('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.textContent= n
  }
}

if ('Gitalk' === 'Gitalk' || !true) {
  if (true) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script><script>function loadWaline () {
  function initWaline () {
    const waline = Waline.init(Object.assign({
      el: '#waline-wrap',
      serverURL: 'https://waline-comments-9etq63pcv-wilenwu.vercel.app',
      pageview: false,
      dark: 'html[data-theme="dark"]',
      path: window.location.pathname,
      comment: false,
    }, {"requiredMeta":["monsterid"]}))
  }

  if (typeof Waline === 'object') initWaline()
  else {
    getCSS('https://cdn.jsdelivr.net/npm/@waline/client/dist/waline.min.css').then(() => {
      getScript('https://cdn.jsdelivr.net/npm/@waline/client/dist/waline.min.js').then(initWaline)
    })
  }
}

if ('Gitalk' === 'Waline' || !true) {
  if (true) btf.loadComment(document.getElementById('waline-wrap'),loadWaline)
  else setTimeout(loadWaline, 0)
} else {
  function loadOtherComment () {
    loadWaline()
  }
}</script></div><script src="/js/custom.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><!-- hexo injector body_end start --><script async src="//at.alicdn.com/t/font_2032782_8d5kxvn09md.js"></script><!-- hexo injector body_end end --></body></html>